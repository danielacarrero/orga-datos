{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6639428af3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"tweets_clean_location.csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.dropna()\n",
    "tweets = tweets.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso para obtener la latitud, longitud y dirección en case a su locación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"geolocator = Nominatim(user_agent=\"orga_datos\")\n",
    "def getGeoData(x):\n",
    "    l = geolocator.geocode(x, timeout=20)\n",
    "    if l == None:\n",
    "        return (None, None, None)\n",
    "    return (l.address, l.latitude, l.longitude)\n",
    "\n",
    "tweets[\"address_latitude_longitude\"] = tweets.location.transform(lambda x: getGeoData(x))\n",
    "tweets.head()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de columna latitud y longitud en el dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tweets[\"latitude\"] = tweets.address_latitude_longitude.transform(lambda x: x[1])\n",
    "tweets[\"longitude\"] = tweets.address_latitude_longitude.transform(lambda x: x[2])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso para separar la dirección obtenida de la API en dos columnas: ciudad y país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def getCleanLocation(x):\n",
    "    if x[0] == None and x[1] == None and x[2] == None:\n",
    "        return (None, None)\n",
    "    \n",
    "    splittedAddress = x[0].split(\",\")\n",
    "    \n",
    "    if 0 <= len(splittedAddress) <= 1:\n",
    "        return (None, None)\n",
    "    \n",
    "    return (splittedAddress[0], splittedAddress[-1])\n",
    "    \n",
    "tweets[\"city\"] = \"\"\n",
    "tweets[\"country\"] = \"\"\n",
    "\n",
    "for index, row in tweets.iterrows():\n",
    "    cleanLocation = getCleanLocation(row.address_latitude_longitude)\n",
    "    tweets.at[index,\"city\"], tweets.at[index,\"country\"] = cleanLocation[0], cleanLocation[1]\n",
    "    \n",
    "tweets.to_csv(\"tweets_with_clean_location.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"country\"] = tweets[\"country\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de todos los tweets en base a su longitud y latitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gp.read_file(gp.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "gdf = gp.GeoDataFrame(\n",
    "    tweets, geometry=gp.points_from_xy(tweets.longitude, tweets.latitude))\n",
    "ax = gdf.plot(color=\"k\", figsize=(15, 10), zorder=2, markersize=1)\n",
    "\n",
    "world.plot(ax = ax, figsize=(10, 5), zorder=1, cmap='OrRd', scheme='quantiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de columna color para cada keyword del dataframe existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"color\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateHexaColor(x):\n",
    "    return matplotlib.colors.to_hex([rd.random(), rd.random(), rd.random()])\n",
    "\n",
    "tweetsWithColor = tweets.groupby(\"keyword\").apply(lambda x: generateHexaColor(x)).to_dict()\n",
    "\n",
    "for index, row in tweets.iterrows():\n",
    "    if tweetsWithColor[row.keyword] != None:\n",
    "        tweets.at[index,\"color\"] = tweetsWithColor[row.keyword]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de todos los tweets por keyword en base a su longitud y latitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gp.GeoDataFrame(\n",
    "    tweets, geometry=gp.points_from_xy(tweets.longitude, tweets.latitude))\n",
    "ax = gdf.plot(color=gdf[\"color\"], figsize=(15, 10), zorder=2, markersize=1)\n",
    "\n",
    "world.plot(ax = ax, figsize=(10, 5), zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los tweets que están en USA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA = tweets[tweets[\"country\"] == \"United States of America\"]\n",
    "\n",
    "USAdf = gp.GeoDataFrame(USA, geometry=gp.points_from_xy(USA.longitude, USA.latitude))\n",
    "USAdf.drop_duplicates(\"city\")\n",
    "\n",
    "world = gp.read_file(gp.datasets.get_path(\"naturalearth_lowres\"))\n",
    "ax = world[world.name==\"United States of America\"].plot(color='white',edgecolor='black', figsize=(15,10))\n",
    "\n",
    "visu = USAdf.plot(ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking de las keywords que tienen tweets con una longitud superior al promedio de longitud de todos los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"keyword\"] = tweets[\"keyword\"].str.replace(\"%20\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text_length\"] = tweets[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tweets.loc[tweets[\"text_length\"] > tweets[\"text_length\"].mean()]\n",
    "\n",
    "xGroupBy = x.groupby([\"keyword\"]).agg({\"keyword\": [\"count\"]}).reset_index().keyword.nlargest(10, \"count\")\n",
    "xGroupBy = xGroupBy.rename(columns={\"\": \"keyword\"})\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.tick_params(axis=\"x\", labelsize=15)\n",
    "ax.tick_params(axis=\"y\", labelsize=15)\n",
    "g = sns.barplot(x=xGroupBy[\"count\"], y=xGroupBy[\"keyword\"], orient=\"h\")\n",
    "g.set_title(\"Keywords with text length > text length mean (of all tweets)\", fontsize=15)\n",
    "g.set_xlabel(\"Quantity\", fontsize=18)\n",
    "g.set_ylabel(\"Keyword\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcentaje de tweets que tienen N salto de líneas (en este caso 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = set()\n",
    "\n",
    "def hasNNewLines(line, n):\n",
    "    counter = 0\n",
    "    for c in line:\n",
    "        if c == \"\\n\":\n",
    "            counter += 1\n",
    "    return counter >= n\n",
    "\n",
    "for index, row in tweets.iterrows():\n",
    "    if hasNNewLines(row.text, 3) and not (\"http\" in row.text):\n",
    "        keywords.add(row.keyword)\n",
    "\n",
    "x = tweets.groupby(\"keyword\").count()\n",
    "\n",
    "percentOfPeopleTryingToSendAPoem = (len(keywords) * 100) / x.shape[0]\n",
    "percentOfPeopleTryingToSendAPoem # Como puedo plotear este valor ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking de keywords donde alguno de sus tweets contienen URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterBy = tweets[\"text\"].str.contains('http')\n",
    "\n",
    "textWithURL = tweets[filterBy]\n",
    "textWithURL = textWithURL.groupby(\"keyword\").count().nlargest(10, \"text\")\n",
    "textWithURL.reset_index(inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.tick_params(axis=\"x\", labelsize=15)\n",
    "ax.tick_params(axis=\"y\", labelsize=15)\n",
    "g = sns.barplot(x=textWithURL[\"text\"], y=textWithURL[\"keyword\"], orient=\"h\")\n",
    "g.set_title(\"Keywords where tweets contain URLs\", fontsize=15)\n",
    "g.set_xlabel(\"Quantity\", fontsize=18)\n",
    "g.set_ylabel(\"Keyword\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking de keywords donde alguno de sus tweets contienen tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterByTag = tweets[\"text\"].str.contains(\"@\")\n",
    "\n",
    "tweetsWithTag = tweets[filterByTag]\n",
    "tweetsWithTag = tweetsWithTag.groupby(\"keyword\").count().nlargest(10, \"text\")\n",
    "tweetsWithTag.reset_index(inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.tick_params(axis=\"x\", labelsize=15)\n",
    "ax.tick_params(axis=\"y\", labelsize=15)\n",
    "g = sns.barplot(x=tweetsWithTag[\"text\"], y=tweetsWithTag[\"keyword\"], orient=\"h\")\n",
    "g.set_title(\"Keywords where tweets contain tags\", fontsize=15)\n",
    "g.set_xlabel(\"Quantity\", fontsize=18)\n",
    "g.set_ylabel(\"Keyword\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking de keywords donde alguno de sus tweets contienen hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterByHashtag = tweets[\"text\"].str.contains(\"#\")\n",
    "\n",
    "tweetsWithHashtag = tweets[filterByHashtag]\n",
    "tweetsWithHashtag = tweetsWithHashtag.loc[:, [\"keyword\",\"text\"]].groupby(\"keyword\").count().nlargest(10, \"text\")\n",
    "tweetsWithUpper.reset_index(inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.tick_params(axis=\"x\", labelsize=15)\n",
    "ax.tick_params(axis=\"y\", labelsize=15)\n",
    "g = sns.barplot(x=tweetsWithUpper[\"text\"], y=tweetsWithUpper[\"keyword\"], orient=\"h\")\n",
    "g.set_title(\"Keywords where tweets contain hashtags\", fontsize=15)\n",
    "g.set_xlabel(\"Quantity\", fontsize=18)\n",
    "g.set_ylabel(\"Keyword\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
