{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "from fuzzywuzzy import fuzz #conda install -c conda-forge fuzzywuzzy\n",
    "\n",
    "tweets = pd.read_csv('train.csv')\n",
    "#vista previa de datos\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_key = tweets.loc[:,['keyword','text']]\n",
    "tweets_text_key.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_key = tweets_text_key.dropna()\n",
    "tweets_text_key.keyword.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El texto de un tweet contiene la keyword?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibe un string, que debe contener el substring \"_concat_\" una sola vez y retorna true si lo que precede al\n",
    "#substring está contenido en lo que le sigue\n",
    "def contain_key(s):\n",
    "    x = s.split(\"_concat_\")\n",
    "    if x[0].lower() in x[1].lower():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se indica si la keyword está contenida en el text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_key['concat'] = tweets_text_key.keyword + \"_concat_\"+ tweets_text_key.text\n",
    "tweets_text_key['text_contain_key'] = tweets_text_key.concat.transform(lambda x: contain_key(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 7,7\n",
    "ax = sns.barplot(data = tweets_text_key.text_contain_key.value_counts().reset_index(),x='index',y='text_contain_key')\n",
    "ax.set_title(\"Total de Tweets que Contienen (y que no contienen) la Keyword \")\n",
    "ax.set_ylabel(\"Total de Tweets\")\n",
    "ax.set_xlabel(\"¿El Texto Contiene la Keyword?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupación de keyword por similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibe una lista de keywords y regresa un diccionario cuyas claves son los elementos de la lista pasada y los valores\n",
    "#son las keywords agrupadas que las representa\n",
    "def get_keyword_dic(key_list):\n",
    "    key_dic = {}\n",
    "    unique_list = []\n",
    "    for x in key_list:\n",
    "        z = x\n",
    "        if \"%20\" in x:\n",
    "            z = \" \".join(x.split(\"%20\"))\n",
    "        similarity = 0\n",
    "        value = \"\"\n",
    "        for y in unique_list:\n",
    "            ratio = fuzz.ratio(z,y)\n",
    "            if ratio > similarity:\n",
    "                similarity = ratio\n",
    "                value = y\n",
    "        if similarity > 75:\n",
    "            key_dic[x] = value\n",
    "        else:\n",
    "            key_dic[x] = z\n",
    "            unique_list.append(z)\n",
    "    return key_dic\n",
    "key_grouped = get_keyword_dic(tweets_text_key.keyword.tolist())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupoamiento manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_grouped['blazing'] = 'ablaze'\n",
    "key_grouped['bleeding'] = 'blood'\n",
    "key_grouped['buildings%20on%20fire'] = 'buildings burning'\n",
    "key_grouped['burning%20buildings'] = 'buildings burning'\n",
    "key_grouped['burning'] = 'burned'\n",
    "key_grouped['dead'] = 'death'\n",
    "key_grouped['demolition'] = 'demolish'\n",
    "key_grouped['destruction'] = 'destroy'\n",
    "key_grouped['explosion'] = 'explode'\n",
    "key_grouped['flood'] = 'flooding'\n",
    "key_grouped['floods'] = 'flooding'\n",
    "key_grouped['inundated'] = 'inundation'\n",
    "key_grouped['panic'] = 'panicking'\n",
    "key_grouped['rainstorm'] = 'rainstorm'\n",
    "key_grouped['riot'] = 'rioting'\n",
    "key_grouped['screaming'] = 'screamed'\n",
    "key_grouped['snowstorm'] = 'snowstorm'\n",
    "key_grouped['survivors'] = 'survive'\n",
    "key_grouped['traumatised'] = 'trauma'\n",
    "key_grouped['violent%20storm'] = 'storm'\n",
    "key_grouped['windstorm'] = 'storm'\n",
    "key_grouped['traumatised'] = 'trauma'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_key['keyword_grouped'] = tweets_text_key.keyword.transform(lambda x: key_grouped[x])\n",
    "tweets_text_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
