{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"data/train_pre_processing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas solo con variables numéricas y booleanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features, target = tweets.select_dtypes(include=['float64','int64','bool']).iloc[:,:-1],tweets.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features, target, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con valores por default del LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.693 (std :0.017). Time: 0.18\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "light_model = LGBMClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('Accuracy: %.3f (std :%.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end-start)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas descartando una columna (todas las combinaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_columns = {}\n",
    "\n",
    "for x in range(0,30):\n",
    "    column_list = []\n",
    "    for y in range(0,30):\n",
    "        if y != x:\n",
    "            column_list.append(y)\n",
    "    x_train_columns[x] = column_list\n",
    "\n",
    "def get_dic_acc():\n",
    "    results = {}\n",
    "    results['accuracy'] = []\n",
    "    results['std'] = []\n",
    "    results['time'] = []\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_4_ormore_words</th>\n",
       "      <td>0.693974</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.136329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text</th>\n",
       "      <td>0.693826</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.126967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_5_ormore_words</th>\n",
       "      <td>0.693695</td>\n",
       "      <td>0.016156</td>\n",
       "      <td>0.135257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words</th>\n",
       "      <td>0.693580</td>\n",
       "      <td>0.016874</td>\n",
       "      <td>0.142286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_ormore_words</th>\n",
       "      <td>0.693399</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>0.134584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_words</th>\n",
       "      <td>0.693350</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>0.135639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_5_words</th>\n",
       "      <td>0.693202</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>0.135478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_words</th>\n",
       "      <td>0.692742</td>\n",
       "      <td>0.015241</td>\n",
       "      <td>0.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_words</th>\n",
       "      <td>0.692693</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>0.136584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_orless_words</th>\n",
       "      <td>0.692562</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.138968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy       std      time\n",
       "total_4_ormore_words  0.693974  0.016061  0.136329\n",
       "subjectivity_text     0.693826  0.016843  0.126967\n",
       "total_5_ormore_words  0.693695  0.016156  0.135257\n",
       "total_6_orless_words  0.693580  0.016874  0.142286\n",
       "total_7_ormore_words  0.693399  0.015039  0.134584\n",
       "total_8_words         0.693350  0.016938  0.135639\n",
       "total_5_words         0.693202  0.015872  0.135478\n",
       "total_7_words         0.692742  0.015241  0.137700\n",
       "total_words           0.692693  0.016329  0.136584\n",
       "total_7_orless_words  0.692562  0.015567  0.138968"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "\n",
    "for x in range(0,30):\n",
    "    start = time.time()\n",
    "\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_train_2 = x_train.iloc[:,x_train_columns[x]]\n",
    "    n_scores = cross_val_score(light_model, x_train_2, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(x_train.columns[x])\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "pd.DataFrame(no_column, index=index_no_column).nlargest(10,'accuracy')     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "realizo una prueba eliminando aquellas columnas que no disminuyeron el resultado de Accuracy con tres decimales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.693 (desv:  0.016). Time: 0.12\n"
     ]
    }
   ],
   "source": [
    "x_train_2 = x_train.drop(columns=['total_4_ormore_words','subjectivity_text','total_5_ormore_words','total_6_orless_words','total_7_ormore_words','total_8_words','total_5_words']) \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "light_model = LGBMClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(light_model, x_train_2, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "print('ACC: %.3f (desv:  %.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando parámetros según https://machinelearningmastery.com/configure-gradient-boosting-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "n_estimators_best = 0\n",
    "n_estimators_acc = 0\n",
    "n_estimators_std = 0\n",
    "\n",
    "n_estimators_dic = get_dic_acc()\n",
    "index_n_estimators = []\n",
    "\n",
    "for x in range(100,501,40):\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1, n_estimators = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_n_estimators.append(x)\n",
    "    n_estimators_dic['accuracy'].append(mean)\n",
    "    n_estimators_dic['std'].append(np.std(std))\n",
    "    n_estimators_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > n_estimators_acc) or (mean == n_estimators_acc and std < n_estimators_std): \n",
    "        n_estimators_best = x\n",
    "        n_estimators_acc = mean\n",
    "        n_estimators_std = std\n",
    " \n",
    "    \n",
    "print(\"Best n_estimators: %d\" % (n_estimators_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.693235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.692151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.690049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.688982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.686404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.686256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.685107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.684959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.684401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.683563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.682939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  std      time\n",
       "100  0.693235  0.0  0.137145\n",
       "140  0.692151  0.0  0.203674\n",
       "180  0.690049  0.0  0.282271\n",
       "220  0.688982  0.0  0.279113\n",
       "260  0.686404  0.0  0.376512\n",
       "300  0.686256  0.0  0.357027\n",
       "340  0.685107  0.0  0.421842\n",
       "420  0.684959  0.0  0.513827\n",
       "380  0.684401  0.0  0.587920\n",
       "460  0.683563  0.0  0.581347\n",
       "500  0.682939  0.0  0.617163"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators_df = pd.DataFrame(n_estimators_dic, index=index_n_estimators).nlargest(20,'accuracy')\n",
    "n_estimators_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning_rate: 0.060\n"
     ]
    }
   ],
   "source": [
    "learning_rate_best = 0\n",
    "learning_rate_acc = 0\n",
    "learning_rate_std = 0\n",
    "\n",
    "learning_rate_dic = get_dic_acc()\n",
    "index_learning_rate = []\n",
    "\n",
    "for x in range(1,11,1):\n",
    "    start = time.time()\n",
    "    x = x/100\n",
    "    light_model = LGBMClassifier(random_state=1, n_estimators = n_estimators_best, learning_rate = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_learning_rate.append(x)\n",
    "    learning_rate_dic['accuracy'].append(mean)\n",
    "    learning_rate_dic['std'].append(np.std(std))\n",
    "    learning_rate_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > learning_rate_acc) or (mean == learning_rate_acc and std < learning_rate_std): \n",
    "        learning_rate_best = x\n",
    "        learning_rate_acc = mean\n",
    "        learning_rate_std = std\n",
    " \n",
    "    \n",
    "print(\"Best learning_rate: %.3f\" % (learning_rate_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.695501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.695074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>0.694663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.07</th>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>0.693530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.693235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.690049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.681346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  std      time\n",
       "0.06  0.695796  0.0  0.164012\n",
       "0.05  0.695501  0.0  0.154972\n",
       "0.04  0.695074  0.0  0.164469\n",
       "0.09  0.694663  0.0  0.143728\n",
       "0.07  0.694581  0.0  0.158520\n",
       "0.08  0.693530  0.0  0.146434\n",
       "0.03  0.693300  0.0  0.163415\n",
       "0.10  0.693235  0.0  0.144655\n",
       "0.02  0.690049  0.0  0.175690\n",
       "0.01  0.681346  0.0  0.171309"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate_df = pd.DataFrame(learning_rate_dic, index=index_learning_rate).nlargest(20,'accuracy')\n",
    "learning_rate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando subsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subsample: 0.10\n"
     ]
    }
   ],
   "source": [
    "subsample_best = 0\n",
    "subsample_acc = 0\n",
    "subsample_std = 0\n",
    "\n",
    "subsample_dic = get_dic_acc()\n",
    "index_subsample = []\n",
    "\n",
    "for x in range(1,11,1):\n",
    "    start = time.time()\n",
    "    x = x/10\n",
    "    light_model = LGBMClassifier(random_state=1, n_estimators = n_estimators_best, learning_rate = learning_rate_best,subsample = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_subsample.append(x)\n",
    "    subsample_dic['accuracy'].append(mean)\n",
    "    subsample_dic['std'].append(np.std(std))\n",
    "    subsample_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > subsample_acc) or (mean == subsample_acc and std < subsample_std): \n",
    "        subsample_best = x\n",
    "        subsample_acc = mean\n",
    "        subsample_std = std\n",
    " \n",
    "    \n",
    "print(\"Best subsample: %.2f\" % (subsample_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  std      time\n",
       "0.1  0.695796  0.0  0.152515\n",
       "0.2  0.695796  0.0  0.155383\n",
       "0.3  0.695796  0.0  0.163912\n",
       "0.4  0.695796  0.0  0.149996\n",
       "0.5  0.695796  0.0  0.158340\n",
       "0.6  0.695796  0.0  0.149866\n",
       "0.7  0.695796  0.0  0.154021\n",
       "0.8  0.695796  0.0  0.155414\n",
       "0.9  0.695796  0.0  0.161930\n",
       "1.0  0.695796  0.0  0.150489"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample_df = pd.DataFrame(subsample_dic, index=index_subsample).nlargest(20,'accuracy')\n",
    "subsample_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando num_leaves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num_leaves: 41\n"
     ]
    }
   ],
   "source": [
    "num_leaves_best = 0\n",
    "num_leaves_acc = 0\n",
    "num_leaves_std = 0\n",
    "\n",
    "num_leaves_dic = get_dic_acc()\n",
    "index_num_leaves = []\n",
    "\n",
    "for x in range(21,42,2):\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1, n_estimators = n_estimators_best, learning_rate = learning_rate_best,subsample = subsample_best, num_leaves = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_num_leaves.append(x)\n",
    "    num_leaves_dic['accuracy'].append(mean)\n",
    "    num_leaves_dic['std'].append(np.std(std))\n",
    "    num_leaves_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > num_leaves_acc) or (mean == num_leaves_acc and std < num_leaves_std): \n",
    "        num_leaves_best = x\n",
    "        num_leaves_acc = mean\n",
    "        num_leaves_std = std\n",
    " \n",
    "    \n",
    "print(\"Best num_leaves: %d\" % (num_leaves_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.696371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.696043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.695961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.695796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.695468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.695337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.694745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.694204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.694089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.693415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  std      time\n",
       "41  0.696371  0.0  0.173512\n",
       "37  0.696043  0.0  0.180911\n",
       "35  0.695961  0.0  0.167752\n",
       "31  0.695796  0.0  0.172101\n",
       "39  0.695468  0.0  0.182489\n",
       "33  0.695402  0.0  0.196915\n",
       "23  0.695337  0.0  0.147810\n",
       "25  0.694745  0.0  0.137749\n",
       "27  0.694204  0.0  0.178376\n",
       "29  0.694089  0.0  0.146089\n",
       "21  0.693415  0.0  0.132687"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_leaves_df = pd.DataFrame(num_leaves_dic, index=index_num_leaves).nlargest(20,'accuracy')\n",
    "num_leaves_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 28\n"
     ]
    }
   ],
   "source": [
    "max_depth_best = 0\n",
    "max_depth_acc = 0\n",
    "max_depth_std = 0\n",
    "\n",
    "max_depth_dic = get_dic_acc()\n",
    "index_max_depth = []\n",
    "\n",
    "for x in range(4,41,4):\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1, n_estimators = n_estimators_best, learning_rate = learning_rate_best,subsample = subsample_best, num_leaves = num_leaves_best, max_depth = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_max_depth.append(x)\n",
    "    max_depth_dic['accuracy'].append(mean)\n",
    "    max_depth_dic['std'].append(np.std(std))\n",
    "    max_depth_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > max_depth_acc) or (mean == max_depth_acc and std < max_depth_std): \n",
    "        max_depth_best = x\n",
    "        max_depth_acc = mean\n",
    "        max_depth_std = std\n",
    "    \n",
    "print(\"Best max_depth: %d\" % (max_depth_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.696371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.696371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.696371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.696371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.696240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.695813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.695813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.695222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  std      time\n",
       "28  0.696371  0.0  0.171964\n",
       "32  0.696371  0.0  0.185959\n",
       "36  0.696371  0.0  0.176535\n",
       "40  0.696371  0.0  0.178573\n",
       "24  0.696240  0.0  0.172617\n",
       "20  0.695813  0.0  0.176105\n",
       "16  0.695813  0.0  0.174271\n",
       "12  0.695222  0.0  0.181733\n",
       "8   0.694647  0.0  0.167256\n",
       "4   0.687964  0.0  0.101823"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_df = pd.DataFrame(max_depth_dic, index=index_max_depth).nlargest(20,'accuracy') \n",
    "max_depth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando min_split_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best min_split_gain: 0.20\n"
     ]
    }
   ],
   "source": [
    "min_split_gain_best = 0\n",
    "min_split_gain_acc = 0\n",
    "min_split_gain_std = 0\n",
    "\n",
    "min_split_gain_dic = get_dic_acc()\n",
    "index_min_split_gain = []\n",
    "\n",
    "for x in range(0,10,1):\n",
    "    start = time.time()\n",
    "    x = x/10\n",
    "    light_model = LGBMClassifier(random_state=1, n_estimators = n_estimators_best, learning_rate = learning_rate_best,subsample = subsample_best, num_leaves = num_leaves_best, max_depth = max_depth_best,min_split_gain = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_min_split_gain.append(x)\n",
    "    min_split_gain_dic['accuracy'].append(mean)\n",
    "    min_split_gain_dic['std'].append(np.std(std))\n",
    "    min_split_gain_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > min_split_gain_acc) or (mean == min_split_gain_acc and std < min_split_gain_std): \n",
    "        min_split_gain_best = x\n",
    "        min_split_gain_acc = mean\n",
    "        min_split_gain_std = std\n",
    "    \n",
    "print(\"Best min_split_gain: %.2f\" % (min_split_gain_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.696749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.696371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.696059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.695468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.695369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.694975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.694910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.694647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.693941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.693481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  std      time\n",
       "0.2  0.696749  0.0  0.172912\n",
       "0.0  0.696371  0.0  0.172689\n",
       "0.1  0.696059  0.0  0.174648\n",
       "0.3  0.695468  0.0  0.177527\n",
       "0.6  0.695369  0.0  0.149954\n",
       "0.8  0.694975  0.0  0.131465\n",
       "0.7  0.694910  0.0  0.139592\n",
       "0.4  0.694647  0.0  0.164154\n",
       "0.5  0.693941  0.0  0.162242\n",
       "0.9  0.693481  0.0  0.127322"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_split_gain_df = pd.DataFrame(min_split_gain_dic, index=index_min_split_gain).nlargest(20,'accuracy') \n",
    "min_split_gain_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Grid searh usando valores cercanos a los mejores parámetros encontrados anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = LGBMClassifier(random_state = 1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "n_estimators = n_estimators_df.nlargest(4,'accuracy').index.tolist() \n",
    "learning_rate = learning_rate_df.nlargest(4,'accuracy').index.tolist() \n",
    "subsample = subsample_df.nlargest(3,'accuracy').index.tolist()\n",
    "num_leaves = num_leaves_df.nlargest(3,'accuracy').index.tolist()\n",
    "max_depth = max_depth_df.nlargest(3,'accuracy').index.tolist()\n",
    "min_split_gain_leaf = min_split_gain_df.nlargest(3,'accuracy').index.tolist()\n",
    "\n",
    "\n",
    "grid = {\n",
    "               'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'min_split_gain_leaf': min_split_gain_leaf,\n",
    "               'num_leaves': num_leaves,\n",
    "               'subsample': subsample}\n",
    "start = time.time()\n",
    "grid_serch_CV = GridSearchCV(estimator = light_model, param_grid = grid, cv = cv, n_jobs = 2, scoring = 'accuracy')\n",
    "grid_serch_CV.fit(x_train, y_train)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_split_gain_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split93_test_score</th>\n",
       "      <th>split94_test_score</th>\n",
       "      <th>split95_test_score</th>\n",
       "      <th>split96_test_score</th>\n",
       "      <th>split97_test_score</th>\n",
       "      <th>split98_test_score</th>\n",
       "      <th>split99_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215527</td>\n",
       "      <td>0.042211</td>\n",
       "      <td>0.008707</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.686371</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>0.679803</td>\n",
       "      <td>0.683087</td>\n",
       "      <td>0.707718</td>\n",
       "      <td>0.695041</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209157</td>\n",
       "      <td>0.023953</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.686371</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>0.679803</td>\n",
       "      <td>0.683087</td>\n",
       "      <td>0.707718</td>\n",
       "      <td>0.695041</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208894</td>\n",
       "      <td>0.031604</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.686371</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>0.679803</td>\n",
       "      <td>0.683087</td>\n",
       "      <td>0.707718</td>\n",
       "      <td>0.695041</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.171804</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.702791</td>\n",
       "      <td>0.676519</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.717570</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176943</td>\n",
       "      <td>0.028129</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.702791</td>\n",
       "      <td>0.676519</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.717570</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0.373623</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.688013</td>\n",
       "      <td>0.702791</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.707718</td>\n",
       "      <td>0.693432</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>0.366068</td>\n",
       "      <td>0.060428</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.688013</td>\n",
       "      <td>0.702791</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.691297</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.707718</td>\n",
       "      <td>0.693432</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>0.442704</td>\n",
       "      <td>0.082364</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>37</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.694745</td>\n",
       "      <td>0.015732</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.450730</td>\n",
       "      <td>0.094299</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>37</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.694745</td>\n",
       "      <td>0.015732</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>0.434496</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>37</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.684729</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.694745</td>\n",
       "      <td>0.015732</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.215527      0.042211         0.008707        0.009469   \n",
       "1          0.209157      0.023953         0.007744        0.001197   \n",
       "2          0.208894      0.031604         0.007822        0.001401   \n",
       "3          0.171804      0.020180         0.006941        0.000722   \n",
       "4          0.176943      0.028129         0.007167        0.001478   \n",
       "...             ...           ...              ...             ...   \n",
       "1291       0.373623      0.097637         0.011372        0.006045   \n",
       "1292       0.366068      0.060428         0.010908        0.001260   \n",
       "1293       0.442704      0.082364         0.011890        0.001797   \n",
       "1294       0.450730      0.094299         0.011934        0.002567   \n",
       "1295       0.434496      0.075362         0.011896        0.001635   \n",
       "\n",
       "     param_learning_rate param_max_depth param_min_split_gain_leaf  \\\n",
       "0                   0.06              12                         0   \n",
       "1                   0.06              12                         0   \n",
       "2                   0.06              12                         0   \n",
       "3                   0.06              12                         0   \n",
       "4                   0.06              12                         0   \n",
       "...                  ...             ...                       ...   \n",
       "1291                0.05              28                       0.6   \n",
       "1292                0.05              28                       0.6   \n",
       "1293                0.05              28                       0.6   \n",
       "1294                0.05              28                       0.6   \n",
       "1295                0.05              28                       0.6   \n",
       "\n",
       "     param_n_estimators param_num_leaves param_subsample  ...  \\\n",
       "0                   100               41             0.1  ...   \n",
       "1                   100               41             0.2  ...   \n",
       "2                   100               41             0.3  ...   \n",
       "3                   100               27             0.1  ...   \n",
       "4                   100               27             0.2  ...   \n",
       "...                 ...              ...             ...  ...   \n",
       "1291                220               27             0.2  ...   \n",
       "1292                220               27             0.3  ...   \n",
       "1293                220               37             0.1  ...   \n",
       "1294                220               37             0.2  ...   \n",
       "1295                220               37             0.3  ...   \n",
       "\n",
       "     split93_test_score  split94_test_score  split95_test_score  \\\n",
       "0              0.691297            0.694581            0.686371   \n",
       "1              0.691297            0.694581            0.686371   \n",
       "2              0.691297            0.694581            0.686371   \n",
       "3              0.673235            0.691297            0.694581   \n",
       "4              0.673235            0.691297            0.694581   \n",
       "...                 ...                 ...                 ...   \n",
       "1291           0.681445            0.688013            0.702791   \n",
       "1292           0.681445            0.688013            0.702791   \n",
       "1293           0.684729            0.699507            0.704433   \n",
       "1294           0.684729            0.699507            0.704433   \n",
       "1295           0.684729            0.699507            0.704433   \n",
       "\n",
       "      split96_test_score  split97_test_score  split98_test_score  \\\n",
       "0               0.706076            0.679803            0.683087   \n",
       "1               0.706076            0.679803            0.683087   \n",
       "2               0.706076            0.679803            0.683087   \n",
       "3               0.702791            0.676519            0.681445   \n",
       "4               0.702791            0.676519            0.681445   \n",
       "...                  ...                 ...                 ...   \n",
       "1291            0.689655            0.691297            0.681445   \n",
       "1292            0.689655            0.691297            0.681445   \n",
       "1293            0.696223            0.684729            0.696223   \n",
       "1294            0.696223            0.684729            0.696223   \n",
       "1295            0.696223            0.684729            0.696223   \n",
       "\n",
       "      split99_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.707718         0.695041        0.016181               19  \n",
       "1               0.707718         0.695041        0.016181               19  \n",
       "2               0.707718         0.695041        0.016181               19  \n",
       "3               0.717570         0.692069        0.016180              955  \n",
       "4               0.717570         0.692069        0.016180              955  \n",
       "...                  ...              ...             ...              ...  \n",
       "1291            0.707718         0.693432        0.016881              388  \n",
       "1292            0.707718         0.693432        0.016881              388  \n",
       "1293            0.712644         0.694745        0.015732               46  \n",
       "1294            0.712644         0.694745        0.015732               46  \n",
       "1295            0.712644         0.694745        0.015732               46  \n",
       "\n",
       "[1296 rows x 114 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_serch_CV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"orga_datos\")\n",
    "def getGeoData(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    try:\n",
    "        l = geolocator.geocode(x, timeout=20)\n",
    "    except:\n",
    "        return pd.NA\n",
    "    \n",
    "    if l == None:\n",
    "        return pd.NA\n",
    "    return (l.address, l.latitude, l.longitude)\n",
    "\n",
    "address = tweets.location.transform(lambda x: getGeoData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_with_cv_mean_encoding(column_name):\n",
    "    data = x_train.join(y_train)\n",
    "    total_true = data.groupby(column_name).target.transform(sum).fillna(0)\n",
    "    dic_total = data.groupby(column_name)[column_name].count().to_dict()\n",
    "    total = data[column_name].transform(lambda x: dic_total[x])\n",
    "    total = total.transform(lambda x: x + 1 if x == 1 else x)\n",
    "    \n",
    "    return (total_true - data.target) / (total - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x_train['latitud'] = address.transform(lambda x: 0 if pd.isna(x) else x[1]).astype('float64')\n",
    "x_train['longitud'] = address.transform(lambda x:  0 if pd.isna(x) else x[2]).astype('float64')\n",
    "\n",
    "x_train['country'] = address.transform(lambda x: 'unknown' if pd.isna(x) else x[0].split(\",\")[len(x[0].split(\",\"))-1])\n",
    "x_train['city'] = address.transform(lambda x: 'unknown' if pd.isna(x) else ('unknown' if len(x[0].split(\",\")) < 2 else x[0].split(\",\")[len(x[0].split(\",\"))-2]))\n",
    "x_train['keyword_grouped'] = tweets['keyword_grouped'].fillna('unknown')\n",
    "\n",
    "x_train['country_cv_mean'] = get_column_with_cv_mean_encoding('country')\n",
    "x_train['city_cv_mean'] = get_column_with_cv_mean_encoding('city')\n",
    "x_train['keyword_cv_mean'] = get_column_with_cv_mean_encoding('keyword_grouped')\n",
    "\n",
    "country_cv_mean_dict = x_train.groupby('country').country_cv_mean.mean().to_dict()\n",
    "city_cv_mean_dict = x_train.groupby('city').city_cv_mean.mean().to_dict()\n",
    "keyword_cv_mean_dict = x_train.groupby('keyword_grouped').keyword_cv_mean.mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6090 entries, 6445 to 3582\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   total_words           6090 non-null   int64  \n",
      " 1   len_text              6090 non-null   int64  \n",
      " 2   total_upper_chars     6090 non-null   int64  \n",
      " 3   total_numbers_chars   6090 non-null   int64  \n",
      " 4   total_special_chars   6090 non-null   int64  \n",
      " 5   total_common_chars    6090 non-null   int64  \n",
      " 6   contain_question      6090 non-null   bool   \n",
      " 7   contain_link          6090 non-null   bool   \n",
      " 8   contain_hashtag       6090 non-null   bool   \n",
      " 9   contain_upper_words   6090 non-null   bool   \n",
      " 10  total_3_words         6090 non-null   int64  \n",
      " 11  total_4_words         6090 non-null   int64  \n",
      " 12  total_5_words         6090 non-null   int64  \n",
      " 13  total_6_words         6090 non-null   int64  \n",
      " 14  total_7_words         6090 non-null   int64  \n",
      " 15  total_8_words         6090 non-null   int64  \n",
      " 16  total_3_ormore_words  6090 non-null   int64  \n",
      " 17  total_4_ormore_words  6090 non-null   int64  \n",
      " 18  total_5_ormore_words  6090 non-null   int64  \n",
      " 19  total_6_ormore_words  6090 non-null   int64  \n",
      " 20  total_7_ormore_words  6090 non-null   int64  \n",
      " 21  total_8_ormore_words  6090 non-null   int64  \n",
      " 22  total_3_orless_words  6090 non-null   int64  \n",
      " 23  total_4_orless_words  6090 non-null   int64  \n",
      " 24  total_5_orless_words  6090 non-null   int64  \n",
      " 25  total_6_orless_words  6090 non-null   int64  \n",
      " 26  total_7_orless_words  6090 non-null   int64  \n",
      " 27  total_8_orless_words  6090 non-null   int64  \n",
      " 28  subjectivity_text     6090 non-null   float64\n",
      " 29  polarity_text         6090 non-null   float64\n",
      " 30  latitud               6090 non-null   float64\n",
      " 31  longitud              6090 non-null   float64\n",
      " 32  country_cv_mean       6090 non-null   float64\n",
      " 33  city_cv_mean          6090 non-null   float64\n",
      " 34  keyword_cv_mean       6090 non-null   float64\n",
      "dtypes: bool(4), float64(7), int64(24)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.select_dtypes(include=['float64','int64','bool'])\n",
    "x_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas incluyendo nuevos features con hiperparámetros por default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.983 (desv:  0.005). Time: 0.44\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "light_model = LGBMClassifier(random_state = 1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(light_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "print('ACC: %.3f (desv:  %.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x_test['latitud'] = address.transform(lambda x: 0 if pd.isna(x) else x[1]).astype('float64')\n",
    "x_test['longitud'] = address.transform(lambda x:  0 if pd.isna(x) else x[2]).astype('float64')\n",
    "\n",
    "x_test['country'] = address.transform(lambda x: 'unknown' if pd.isna(x) else x[0].split(\",\")[len(x[0].split(\",\"))-1])\n",
    "x_test['city'] = address.transform(lambda x: 'unknown' if pd.isna(x) else ('unknown' if len(x[0].split(\",\")) < 2 else x[0].split(\",\")[len(x[0].split(\",\"))-2]))\n",
    "x_test['keyword_grouped'] = tweets['keyword_grouped'].fillna('unknown')\n",
    "\n",
    "x_test['country_cv_mean'] = x_test.country.transform(lambda x: country_cv_mean_dict[x] if x in country_cv_mean_dict else country_cv_mean_dict['unknown'])\n",
    "x_test['city_cv_mean'] = x_test.city.transform(lambda x: city_cv_mean_dict[x] if x in city_cv_mean_dict else city_cv_mean_dict['unknown'])\n",
    "x_test['keyword_cv_mean'] = x_test.keyword_grouped.transform(lambda x: keyword_cv_mean_dict[x] if x in keyword_cv_mean_dict else keyword_cv_mean_dict['unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.586343\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test.select_dtypes(include=['float64','int64','bool'])\n",
    "light_model = LGBMClassifier(random_state=1)\n",
    "light_model.fit(x_train, y_train)\n",
    "preds = light_model.predict(x_test)\n",
    "acc = accuracy_score(preds,y_test)\n",
    "print(\"ACC: %f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pruebas sacando features relacionados a location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.676953\n"
     ]
    }
   ],
   "source": [
    "light_model = LGBMClassifier(random_state=1)\n",
    "light_model.fit(x_train.drop(columns=['city_cv_mean','country_cv_mean','longitud','latitud']), y_train)\n",
    "preds = light_model.predict(x_test.drop(columns=['city_cv_mean','country_cv_mean','longitud','latitud']))\n",
    "acc = accuracy_score(preds,y_test)\n",
    "print(\"ACC: %f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con diferentes hiperparámetros (usando los mejores anteriores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = LGBMClassifier(random_state = 1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "n_estimators = n_estimators_df.nlargest(4,'accuracy').index.tolist() \n",
    "learning_rate = learning_rate_df.nlargest(4,'accuracy').index.tolist() \n",
    "subsample = subsample_df.nlargest(3,'accuracy').index.tolist()\n",
    "num_leaves = num_leaves_df.nlargest(3,'accuracy').index.tolist()\n",
    "max_depth = max_depth_df.nlargest(3,'accuracy').index.tolist()\n",
    "min_split_gain_leaf = min_split_gain_df.nlargest(3,'accuracy').index.tolist()\n",
    "\n",
    "\n",
    "grid = {\n",
    "               'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'min_split_gain_leaf': min_split_gain_leaf,\n",
    "               'num_leaves': num_leaves,\n",
    "               'subsample': subsample}\n",
    "start = time.time()\n",
    "grid_serch_CV = GridSearchCV(estimator = light_model, param_grid = grid, cv = cv, n_jobs = 2, scoring = 'accuracy')\n",
    "grid_serch_CV.fit(x_train, y_train)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_split_gain_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split93_test_score</th>\n",
       "      <th>split94_test_score</th>\n",
       "      <th>split95_test_score</th>\n",
       "      <th>split96_test_score</th>\n",
       "      <th>split97_test_score</th>\n",
       "      <th>split98_test_score</th>\n",
       "      <th>split99_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.551519</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0.548723</td>\n",
       "      <td>0.073697</td>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0.538568</td>\n",
       "      <td>0.038767</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.545359</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0.544629</td>\n",
       "      <td>0.087835</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.537407</td>\n",
       "      <td>0.040648</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0.534416</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.546641</td>\n",
       "      <td>0.056547</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.537269</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.08</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0.535775</td>\n",
       "      <td>0.038065</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.08</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "786       0.551519      0.057377         0.011268        0.001505   \n",
       "787       0.548723      0.073697         0.011463        0.001613   \n",
       "788       0.538568      0.038767         0.011131        0.000873   \n",
       "822       0.545359      0.050202         0.011132        0.000984   \n",
       "823       0.544629      0.087835         0.011456        0.001509   \n",
       "824       0.537407      0.040648         0.011247        0.001563   \n",
       "858       0.534416      0.037560         0.011758        0.002347   \n",
       "859       0.546641      0.056547         0.011360        0.002424   \n",
       "860       0.537269      0.036335         0.011371        0.001882   \n",
       "894       0.535775      0.038065         0.011401        0.002241   \n",
       "\n",
       "    param_learning_rate param_max_depth param_min_split_gain_leaf  \\\n",
       "786                0.08              20                         0   \n",
       "787                0.08              20                         0   \n",
       "788                0.08              20                         0   \n",
       "822                0.08              20                       0.1   \n",
       "823                0.08              20                       0.1   \n",
       "824                0.08              20                       0.1   \n",
       "858                0.08              20                       0.6   \n",
       "859                0.08              20                       0.6   \n",
       "860                0.08              20                       0.6   \n",
       "894                0.08              28                         0   \n",
       "\n",
       "    param_n_estimators param_num_leaves param_subsample  ...  \\\n",
       "786                220               27             0.1  ...   \n",
       "787                220               27             0.2  ...   \n",
       "788                220               27             0.3  ...   \n",
       "822                220               27             0.1  ...   \n",
       "823                220               27             0.2  ...   \n",
       "824                220               27             0.3  ...   \n",
       "858                220               27             0.1  ...   \n",
       "859                220               27             0.2  ...   \n",
       "860                220               27             0.3  ...   \n",
       "894                220               27             0.1  ...   \n",
       "\n",
       "    split93_test_score  split94_test_score  split95_test_score  \\\n",
       "786           0.983580            0.980296            0.990148   \n",
       "787           0.983580            0.980296            0.990148   \n",
       "788           0.983580            0.980296            0.990148   \n",
       "822           0.983580            0.980296            0.990148   \n",
       "823           0.983580            0.980296            0.990148   \n",
       "824           0.983580            0.980296            0.990148   \n",
       "858           0.983580            0.980296            0.990148   \n",
       "859           0.983580            0.980296            0.990148   \n",
       "860           0.983580            0.980296            0.990148   \n",
       "894           0.980296            0.980296            0.983580   \n",
       "\n",
       "     split96_test_score  split97_test_score  split98_test_score  \\\n",
       "786            0.988506            0.985222            0.990148   \n",
       "787            0.988506            0.985222            0.990148   \n",
       "788            0.988506            0.985222            0.990148   \n",
       "822            0.988506            0.985222            0.990148   \n",
       "823            0.988506            0.985222            0.990148   \n",
       "824            0.988506            0.985222            0.990148   \n",
       "858            0.988506            0.985222            0.990148   \n",
       "859            0.988506            0.985222            0.990148   \n",
       "860            0.988506            0.985222            0.990148   \n",
       "894            0.988506            0.985222            0.990148   \n",
       "\n",
       "     split99_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "786            0.985222         0.985911        0.004867                1  \n",
       "787            0.985222         0.985911        0.004867                1  \n",
       "788            0.985222         0.985911        0.004867                1  \n",
       "822            0.985222         0.985911        0.004867                1  \n",
       "823            0.985222         0.985911        0.004867                1  \n",
       "824            0.985222         0.985911        0.004867                1  \n",
       "858            0.985222         0.985911        0.004867                1  \n",
       "859            0.985222         0.985911        0.004867                1  \n",
       "860            0.985222         0.985911        0.004867                1  \n",
       "894            0.985222         0.985911        0.004900                1  \n",
       "\n",
       "[10 rows x 114 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_serch_CV.cv_results_).nlargest(10,'mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con otros features (sin los derivados de location anteriores y sin los cv mean encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2 = pd.read_csv(\"data/train_pre_processing_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features_2, target_2 = tweets_2.select_dtypes(include=['float64','int64','bool']).iloc[:,:-1],tweets_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2_train, x_2_test, y_2_train, y_2_test = train_test_split(x_features_2, target_2, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6090 entries, 6445 to 3582\n",
      "Data columns (total 44 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   text_contain_keyword               6090 non-null   bool   \n",
      " 1   total_words                        6090 non-null   int64  \n",
      " 2   len_text                           6090 non-null   int64  \n",
      " 3   total_upper_chars                  6090 non-null   int64  \n",
      " 4   total_numbers_chars                6090 non-null   int64  \n",
      " 5   total_special_chars                6090 non-null   int64  \n",
      " 6   total_common_chars                 6090 non-null   int64  \n",
      " 7   contain_question                   6090 non-null   bool   \n",
      " 8   contain_link                       6090 non-null   bool   \n",
      " 9   contain_hashtag                    6090 non-null   bool   \n",
      " 10  contain_upper_words                6090 non-null   bool   \n",
      " 11  total_3_words                      6090 non-null   int64  \n",
      " 12  total_4_words                      6090 non-null   int64  \n",
      " 13  total_5_words                      6090 non-null   int64  \n",
      " 14  total_6_words                      6090 non-null   int64  \n",
      " 15  total_7_words                      6090 non-null   int64  \n",
      " 16  total_8_words                      6090 non-null   int64  \n",
      " 17  total_3_ormore_words               6090 non-null   int64  \n",
      " 18  total_4_ormore_words               6090 non-null   int64  \n",
      " 19  total_5_ormore_words               6090 non-null   int64  \n",
      " 20  total_6_ormore_words               6090 non-null   int64  \n",
      " 21  total_7_ormore_words               6090 non-null   int64  \n",
      " 22  total_8_ormore_words               6090 non-null   int64  \n",
      " 23  total_3_orless_words               6090 non-null   int64  \n",
      " 24  total_4_orless_words               6090 non-null   int64  \n",
      " 25  total_5_orless_words               6090 non-null   int64  \n",
      " 26  total_6_orless_words               6090 non-null   int64  \n",
      " 27  total_7_orless_words               6090 non-null   int64  \n",
      " 28  total_8_orless_words               6090 non-null   int64  \n",
      " 29  subjectivity_text                  6090 non-null   float64\n",
      " 30  polarity_text                      6090 non-null   float64\n",
      " 31  stopword_count                     6090 non-null   int64  \n",
      " 32  unique_word_count                  6090 non-null   int64  \n",
      " 33  text_contain_word_location         6090 non-null   bool   \n",
      " 34  len_location_cero_default          6090 non-null   int64  \n",
      " 35  len_location_mean_default          6090 non-null   int64  \n",
      " 36  total_words_location_cero_default  6090 non-null   int64  \n",
      " 37  total_words_location_mean_default  6090 non-null   int64  \n",
      " 38  text_contain_keyword_similarity    6090 non-null   bool   \n",
      " 39  text_similarity_keyword            6090 non-null   int64  \n",
      " 40  text_best_similarity_keyword       6090 non-null   int64  \n",
      " 41  text_similarity_location           6090 non-null   int64  \n",
      " 42  text_best_similarity_location      6090 non-null   int64  \n",
      " 43  ratio_short_big_words              6090 non-null   float64\n",
      "dtypes: bool(7), float64(3), int64(34)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "x_2_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pruebas con valores por default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.712 (std :0.016). Time: 0.25\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "light_model = LGBMClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "n_scores = cross_val_score(light_model, x_2_train, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('Accuracy: %.3f (std :%.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search con los mejores parámetros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = LGBMClassifier(random_state = 1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "n_estimators = n_estimators_df.nlargest(4,'accuracy').index.tolist() \n",
    "learning_rate = learning_rate_df.nlargest(4,'accuracy').index.tolist() \n",
    "subsample = subsample_df.nlargest(3,'accuracy').index.tolist()\n",
    "num_leaves = num_leaves_df.nlargest(3,'accuracy').index.tolist()\n",
    "max_depth = max_depth_df.nlargest(3,'accuracy').index.tolist()\n",
    "min_split_gain_leaf = min_split_gain_df.nlargest(3,'accuracy').index.tolist()\n",
    "\n",
    "\n",
    "grid = {\n",
    "               'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'min_split_gain_leaf': min_split_gain_leaf,\n",
    "               'num_leaves': num_leaves,\n",
    "               'subsample': subsample}\n",
    "start = time.time()\n",
    "grid_serch_CV_3 = GridSearchCV(estimator = light_model, param_grid = grid, cv = cv, n_jobs = 2, scoring = 'accuracy')\n",
    "grid_serch_CV_3.fit(x_2_train, y_2_train)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((end-start)/3600)\n",
    "pd.DataFrame(grid_serch_CV_3.cv_results_).nlargest(10,'mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas eliminando features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminando una sola columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_columns = {}\n",
    "\n",
    "for x in range(0,len(x_2_train.columns)):\n",
    "    column_list = []\n",
    "    for y in range(0,len(x_2_train.columns)):\n",
    "        if y != x:\n",
    "            column_list.append(y)\n",
    "    x_train_columns[x] = column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "\n",
    "for x in range(0,len(x_2_train.columns)):\n",
    "    start = time.time()\n",
    "\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_2_train_2 = x_2_train.iloc[:,x_train_columns[x]]\n",
    "    n_scores = cross_val_score(light_model, x_2_train_2, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(x_2_train.columns[x])\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "one_column_deleted = pd.DataFrame(no_column, index=index_no_column) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_7_words</th>\n",
       "      <td>0.731199</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.175553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_ormore_words</th>\n",
       "      <td>0.730837</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>0.176326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_5_orless_words</th>\n",
       "      <td>0.730772</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>0.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_best_similarity_location</th>\n",
       "      <td>0.730657</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.176485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_4_ormore_words</th>\n",
       "      <td>0.730542</td>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.174773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_location_cero_default</th>\n",
       "      <td>0.730427</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>0.178933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_upper_chars</th>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.180205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words</th>\n",
       "      <td>0.730131</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>0.182965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_hashtag</th>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>0.185678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_ormore_words</th>\n",
       "      <td>0.729918</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>0.185775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy       std      time\n",
       "total_7_words                  0.731199  0.015945  0.175553\n",
       "total_6_ormore_words           0.730837  0.014928  0.176326\n",
       "total_5_orless_words           0.730772  0.015703  0.169900\n",
       "text_best_similarity_location  0.730657  0.015656  0.176485\n",
       "total_4_ormore_words           0.730542  0.015892  0.174773\n",
       "len_location_cero_default      0.730427  0.014328  0.178933\n",
       "total_upper_chars              0.730263  0.015400  0.180205\n",
       "total_6_orless_words           0.730131  0.017886  0.182965\n",
       "contain_hashtag                0.730000  0.014951  0.185678\n",
       "total_3_ormore_words           0.729918  0.016253  0.185775"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_column_deleted.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminando dos columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_two_columns(column_list):\n",
    "    two_columns_list = []\n",
    "    for x in range(0,len(column_list)):\n",
    "        for y in range(1,len(column_list)-x):\n",
    "            columns = []\n",
    "            columns.append(column_list[x])\n",
    "            columns.append(column_list[x+y])\n",
    "            two_columns_list.append(columns)\n",
    "    return two_columns_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "columns_to_delete_list = get_all_two_columns(range(0,len(x_2_train.columns)))\n",
    "\n",
    "for x in columns_to_delete_list:\n",
    "    start = time.time()\n",
    "\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_2_train_2 = x_2_train.drop(columns= x_2_train.iloc[:,x].columns.tolist())\n",
    "    n_scores = cross_val_score(light_model, x_2_train_2, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(\", \".join(x_2_train.iloc[:,x].columns.tolist()))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "two_column_deleted = pd.DataFrame(no_column, index=index_no_column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words, subjectivity_text</th>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>0.158562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_best_similarity_location</th>\n",
       "      <td>0.732250</td>\n",
       "      <td>0.016499</td>\n",
       "      <td>0.156382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_similarity_location, text_best_similarity_location</th>\n",
       "      <td>0.732036</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>0.166033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_common_chars, total_4_words</th>\n",
       "      <td>0.731823</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.165270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_4_ormore_words, subjectivity_text</th>\n",
       "      <td>0.731724</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.158264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_words, text_similarity_location</th>\n",
       "      <td>0.731675</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>0.166719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.731675</td>\n",
       "      <td>0.016707</td>\n",
       "      <td>0.167279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_words, total_8_words</th>\n",
       "      <td>0.731626</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.169751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_words, subjectivity_text</th>\n",
       "      <td>0.731609</td>\n",
       "      <td>0.015812</td>\n",
       "      <td>0.159254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_4_words, total_8_words</th>\n",
       "      <td>0.731576</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.170151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "total_6_orless_words, subjectivity_text             0.732562  0.016187   \n",
       "subjectivity_text, text_best_similarity_location    0.732250  0.016499   \n",
       "text_similarity_location, text_best_similarity_...  0.732036  0.015768   \n",
       "total_common_chars, total_4_words                   0.731823  0.017137   \n",
       "total_4_ormore_words, subjectivity_text             0.731724  0.015787   \n",
       "total_7_words, text_similarity_location             0.731675  0.016149   \n",
       "total_4_orless_words, len_location_mean_default     0.731675  0.016707   \n",
       "total_7_words, total_8_words                        0.731626  0.016029   \n",
       "total_7_words, subjectivity_text                    0.731609  0.015812   \n",
       "total_4_words, total_8_words                        0.731576  0.016034   \n",
       "\n",
       "                                                        time  \n",
       "total_6_orless_words, subjectivity_text             0.158562  \n",
       "subjectivity_text, text_best_similarity_location    0.156382  \n",
       "text_similarity_location, text_best_similarity_...  0.166033  \n",
       "total_common_chars, total_4_words                   0.165270  \n",
       "total_4_ormore_words, subjectivity_text             0.158264  \n",
       "total_7_words, text_similarity_location             0.166719  \n",
       "total_4_orless_words, len_location_mean_default     0.167279  \n",
       "total_7_words, total_8_words                        0.169751  \n",
       "total_7_words, subjectivity_text                    0.159254  \n",
       "total_4_words, total_8_words                        0.170151  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_column_deleted.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toman 10 de los features en cuya ausencia en la prueba  anterior no empeoró los resultados y se hacen pruebas eliminando todas las combinaciones posibles de estos 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subconjuntos(c):\n",
    "    if len(c) == 0:\n",
    "        return [[]]\n",
    "    r = subconjuntos(c[:-1])\n",
    "    return r + [s + [c[-1]] for s in r]\n",
    "\n",
    "bad_columns = subconjuntos(['total_6_orless_words', 'subjectivity_text', 'text_best_similarity_location','text_similarity_location','total_common_chars', 'total_4_words','total_4_ormore_words','total_7_words','total_4_orless_words', 'len_location_mean_default'])\n",
    "bad_columns.remove([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in bad_columns:\n",
    "    start = time.time()\n",
    "\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_2_train_2 = x_2_train.drop(columns= x)\n",
    "    n_scores = cross_val_score(light_model, x_2_train_2, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "all_bad_column_deleted = pd.DataFrame(no_column, index=index_no_column) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_words, total_4_ormore_words, total_7_words, total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.735222</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.150535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_ormore_words, total_7_words, total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.735172</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>0.144412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_words, total_7_words, total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.735090</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.143564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words, subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_words, total_7_words, total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.149217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_words, total_4_ormore_words, total_7_words, len_location_mean_default</th>\n",
       "      <td>0.734663</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.145873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words, subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_words, total_4_ormore_words, total_7_words, total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.734647</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.138616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words, subjectivity_text, text_best_similarity_location, text_similarity_location, total_common_chars, total_4_words, total_7_words, total_4_orless_words, len_location_mean_default</th>\n",
       "      <td>0.734614</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.141391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_best_similarity_location, text_similarity_location, total_4_ormore_words, total_7_words, len_location_mean_default</th>\n",
       "      <td>0.734516</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>0.147075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_text, text_similarity_location, total_4_words, total_4_ormore_words, total_7_words, len_location_mean_default</th>\n",
       "      <td>0.734401</td>\n",
       "      <td>0.015730</td>\n",
       "      <td>0.147504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_orless_words, subjectivity_text, text_best_similarity_location, total_4_words, total_4_ormore_words, total_7_words, len_location_mean_default</th>\n",
       "      <td>0.734351</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>0.146812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "subjectivity_text, text_best_similarity_locatio...  0.735222  0.015931   \n",
       "subjectivity_text, text_best_similarity_locatio...  0.735172  0.014615   \n",
       "subjectivity_text, text_best_similarity_locatio...  0.735090  0.014833   \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.734762  0.015493   \n",
       "subjectivity_text, text_best_similarity_locatio...  0.734663  0.016667   \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.734647  0.015384   \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.734614  0.015629   \n",
       "subjectivity_text, text_best_similarity_locatio...  0.734516  0.016164   \n",
       "subjectivity_text, text_similarity_location, to...  0.734401  0.015730   \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.734351  0.016236   \n",
       "\n",
       "                                                        time  \n",
       "subjectivity_text, text_best_similarity_locatio...  0.150535  \n",
       "subjectivity_text, text_best_similarity_locatio...  0.144412  \n",
       "subjectivity_text, text_best_similarity_locatio...  0.143564  \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.149217  \n",
       "subjectivity_text, text_best_similarity_locatio...  0.145873  \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.138616  \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.141391  \n",
       "subjectivity_text, text_best_similarity_locatio...  0.147075  \n",
       "subjectivity_text, text_similarity_location, to...  0.147504  \n",
       "total_6_orless_words, subjectivity_text, text_b...  0.146812  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bad_column_deleted.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de features que añadieron mayor cantidad de ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "x_2_train.drop(columns=['subjectivity_text', 'text_best_similarity_location', 'text_similarity_location', 'total_4_words', 'total_4_ormore_words', 'total_7_words', 'total_4_orless_words', 'len_location_mean_default'],inplace = True)\n",
    "x_2_test.drop( columns=['subjectivity_text', 'text_best_similarity_location', 'text_similarity_location', 'total_4_words', 'total_4_ormore_words', 'total_7_words', 'total_4_orless_words', 'len_location_mean_default'],inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo la linea del TP1, sabemos que hay palabras más frecuentes en tweets verdaderos. No es posible usar las encontradas en el TP1 debido a que estos features tienen conocimiento del target y corresponden al mismo set que se dividió train y test set, por lo tanto generaremos unos nuevos a partir del train set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de features a partir de las palabras más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = {}\n",
    "for x in x_2_train.join(tweets_2.loc[:,['text','target']]).loc[:,['text','target']].iterrows():\n",
    "    for word in re.split(' |\\'|\\*|\\n|:|#|@|-|\\?|\\.|,|[|]|!|¡',x[1]['text']):\n",
    "        word = word.lower()\n",
    "        if len(word) < 4:\n",
    "            continue\n",
    "        if not word in words_dict:\n",
    "            words_dict[word] = [0,0]\n",
    "        if x[1]['target'] == 1:\n",
    "            words_dict[word][0] = words_dict[word][0] + 1\n",
    "        else:\n",
    "            words_dict[word][1] = words_dict[word][1] + 1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_dict,index=['total_target_true','total_target_false']).transpose()\n",
    "words_df = words_df.loc[(words_df.total_target_true + words_df.total_target_false) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_100_true = []\n",
    "words_100_false = []\n",
    "words_90_true = []\n",
    "words_90_false = []\n",
    "words_85_true = []\n",
    "words_85_false = []\n",
    "words_80_true = []\n",
    "words_80_false = []\n",
    "words_75_true = []\n",
    "words_75_false = []\n",
    "words_70_true = []\n",
    "words_70_false = []\n",
    "\n",
    "\n",
    "for word in words_df.iterrows():\n",
    "    false = word[1]['total_target_false']\n",
    "    true = word[1]['total_target_true']\n",
    "    \n",
    "    if true == 0:\n",
    "        words_100_false.append(word[0])\n",
    "        \n",
    "    if false == 0:\n",
    "        words_100_true.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.9:\n",
    "        words_90_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.9:\n",
    "        words_90_false.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.85:\n",
    "        words_85_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.85:\n",
    "        words_85_false.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.8:\n",
    "        words_80_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.8:\n",
    "        words_80_false.append(word[0])\n",
    "\n",
    "    if true / (true + false) >= 0.75:\n",
    "        words_75_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.75:\n",
    "        words_75_false.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.7:\n",
    "        words_70_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.7:\n",
    "        words_70_false.append(word[0])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_contain_word_list(s,l):\n",
    "    for word in l:\n",
    "        if word.lower() in s.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "x_2_train['contain_words_100_true'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_100_true))\n",
    "x_2_train['contain_words_100_false'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_100_false))\n",
    "x_2_train['contain_words_90_true'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_90_true))\n",
    "x_2_train['contain_words_90_false'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_90_false))\n",
    "x_2_train['contain_words_85_true'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_85_true))\n",
    "x_2_train['contain_words_85_false'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_85_false))\n",
    "x_2_train['contain_words_80_true'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_80_true))\n",
    "x_2_train['contain_words_80_false'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_80_false))\n",
    "x_2_train['contain_words_75_true'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_75_true))\n",
    "x_2_train['contain_words_75_false'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_75_false))\n",
    "x_2_train['contain_words_70_true'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_70_true))\n",
    "x_2_train['contain_words_70_false'] = x_2_train.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_70_false))\n",
    "                                                                                     \n",
    "                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790 (std :0.016). Time: 0.20\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "light_model = LGBMClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "n_scores = cross_val_score(light_model, x_2_train, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('Accuracy: %.3f (std :%.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "x_2_test['contain_words_100_true'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_100_true))\n",
    "x_2_test['contain_words_100_false'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_100_false))\n",
    "x_2_test['contain_words_90_true'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_90_true))\n",
    "x_2_test['contain_words_90_false'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_90_false)) \n",
    "x_2_test['contain_words_85_true'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_85_true))\n",
    "x_2_test['contain_words_85_false'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_85_false))\n",
    "x_2_test['contain_words_80_true'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_80_true))\n",
    "x_2_test['contain_words_80_false'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_80_false))\n",
    "x_2_test['contain_words_75_true'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_75_true))\n",
    "x_2_test['contain_words_75_false'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_75_false))\n",
    "x_2_test['contain_words_70_true'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_70_true))\n",
    "x_2_test['contain_words_70_false'] = x_2_test.join(tweets_2.loc[:,['text']]).text.transform(lambda x: text_contain_word_list(x,words_70_false))                                                                                     \n",
    "                                                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.769534\n"
     ]
    }
   ],
   "source": [
    "light_model = LGBMClassifier(random_state=1)\n",
    "light_model.fit(x_2_train, y_2_train)\n",
    "preds = light_model.predict(x_2_test)\n",
    "acc = accuracy_score(preds,y_2_test)\n",
    "print(\"ACC: %f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se aplica otra ronda de features que pudieran estar causando ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "columns_to_delete_list = get_all_two_columns(range(0,len(x_2_train.columns)))\n",
    "\n",
    "for x in columns_to_delete_list:\n",
    "    start = time.time()\n",
    "\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_2_train_2 = x_2_train.drop(columns= x_2_train.iloc[:,x].columns.tolist())\n",
    "    n_scores = cross_val_score(light_model, x_2_train_2, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(\", \".join(x_2_train.iloc[:,x].columns.tolist()))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "two_column_deleted_2 = pd.DataFrame(no_column, index=index_no_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false</th>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>0.207089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_words, contain_words_85_true</th>\n",
       "      <td>0.791888</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.159134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_words, total_7_ormore_words</th>\n",
       "      <td>0.791806</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.160728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_100_false, contain_words_85_true</th>\n",
       "      <td>0.791511</td>\n",
       "      <td>0.015161</td>\n",
       "      <td>0.160883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_common_chars, total_7_orless_words</th>\n",
       "      <td>0.791494</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.160678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_ormore_words, contain_words_100_true</th>\n",
       "      <td>0.791478</td>\n",
       "      <td>0.014966</td>\n",
       "      <td>0.159695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_100_false, contain_words_75_false</th>\n",
       "      <td>0.791429</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.160631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_upper_chars, text_contain_keyword_similarity</th>\n",
       "      <td>0.791396</td>\n",
       "      <td>0.015688</td>\n",
       "      <td>0.178859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_special_chars, text_contain_keyword_similarity</th>\n",
       "      <td>0.791379</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.163718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_7_ormore_words, total_7_orless_words</th>\n",
       "      <td>0.791379</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.163535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "len_text, contain_words_75_false                    0.792348  0.015111   \n",
       "total_8_words, contain_words_85_true                0.791888  0.014553   \n",
       "total_8_words, total_7_ormore_words                 0.791806  0.015795   \n",
       "contain_words_100_false, contain_words_85_true      0.791511  0.015161   \n",
       "total_common_chars, total_7_orless_words            0.791494  0.015728   \n",
       "total_8_ormore_words, contain_words_100_true        0.791478  0.014966   \n",
       "contain_words_100_false, contain_words_75_false     0.791429  0.014353   \n",
       "total_upper_chars, text_contain_keyword_similarity  0.791396  0.015688   \n",
       "total_special_chars, text_contain_keyword_simil...  0.791379  0.015052   \n",
       "total_7_ormore_words, total_7_orless_words          0.791379  0.013986   \n",
       "\n",
       "                                                        time  \n",
       "len_text, contain_words_75_false                    0.207089  \n",
       "total_8_words, contain_words_85_true                0.159134  \n",
       "total_8_words, total_7_ormore_words                 0.160728  \n",
       "contain_words_100_false, contain_words_85_true      0.160883  \n",
       "total_common_chars, total_7_orless_words            0.160678  \n",
       "total_8_ormore_words, contain_words_100_true        0.159695  \n",
       "contain_words_100_false, contain_words_75_false     0.160631  \n",
       "total_upper_chars, text_contain_keyword_similarity  0.178859  \n",
       "total_special_chars, text_contain_keyword_simil...  0.163718  \n",
       "total_7_ormore_words, total_7_orless_words          0.163535  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_column_deleted_2.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_columns = subconjuntos(['len_text', 'contain_words_75_false','total_8_words', 'contain_words_85_true', 'total_7_ormore_words','contain_words_100_false','total_common_chars', 'total_7_orless_words','total_8_ormore_words', 'contain_words_100_true'])\n",
    "bad_columns.remove([])\n",
    "\n",
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in bad_columns:\n",
    "    start = time.time()\n",
    "\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_2_train_2 = x_2_train.drop(columns= x)\n",
    "    n_scores = cross_val_score(light_model, x_2_train_2, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "all_bad_column_deleted_2 = pd.DataFrame(no_column, index=index_no_column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false, total_8_words, total_common_chars, total_8_ormore_words</th>\n",
       "      <td>0.792594</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.148443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false, total_7_ormore_words, total_common_chars, total_7_orless_words</th>\n",
       "      <td>0.792365</td>\n",
       "      <td>0.014527</td>\n",
       "      <td>0.149968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false</th>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>0.177048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false, total_7_ormore_words, contain_words_100_false, total_common_chars, total_7_orless_words</th>\n",
       "      <td>0.792332</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.147492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_85_true, total_7_ormore_words, total_common_chars, total_8_ormore_words</th>\n",
       "      <td>0.792315</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.154439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false, contain_words_85_true, total_7_ormore_words, total_common_chars, total_7_orless_words</th>\n",
       "      <td>0.792184</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.144476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false, contain_words_85_true, contain_words_100_false, total_common_chars, total_8_ormore_words</th>\n",
       "      <td>0.792167</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.147712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_75_false, total_7_ormore_words, contain_words_100_false, total_7_orless_words, total_8_ormore_words, contain_words_100_true</th>\n",
       "      <td>0.792167</td>\n",
       "      <td>0.015742</td>\n",
       "      <td>0.152341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, contain_words_75_false, total_8_words, contain_words_85_true, total_7_ormore_words, total_common_chars, total_7_orless_words</th>\n",
       "      <td>0.792151</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.142735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_text, total_8_words, total_7_ormore_words, total_common_chars</th>\n",
       "      <td>0.792151</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.150232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "len_text, contain_words_75_false, total_8_words...  0.792594  0.015830   \n",
       "len_text, contain_words_75_false, total_7_ormor...  0.792365  0.014527   \n",
       "len_text, contain_words_75_false                    0.792348  0.015111   \n",
       "len_text, contain_words_75_false, total_7_ormor...  0.792332  0.014605   \n",
       "contain_words_85_true, total_7_ormore_words, to...  0.792315  0.014690   \n",
       "len_text, contain_words_75_false, contain_words...  0.792184  0.013999   \n",
       "len_text, contain_words_75_false, contain_words...  0.792167  0.015000   \n",
       "contain_words_75_false, total_7_ormore_words, c...  0.792167  0.015742   \n",
       "len_text, contain_words_75_false, total_8_words...  0.792151  0.015052   \n",
       "len_text, total_8_words, total_7_ormore_words, ...  0.792151  0.014828   \n",
       "\n",
       "                                                        time  \n",
       "len_text, contain_words_75_false, total_8_words...  0.148443  \n",
       "len_text, contain_words_75_false, total_7_ormor...  0.149968  \n",
       "len_text, contain_words_75_false                    0.177048  \n",
       "len_text, contain_words_75_false, total_7_ormor...  0.147492  \n",
       "contain_words_85_true, total_7_ormore_words, to...  0.154439  \n",
       "len_text, contain_words_75_false, contain_words...  0.144476  \n",
       "len_text, contain_words_75_false, contain_words...  0.147712  \n",
       "contain_words_75_false, total_7_ormore_words, c...  0.152341  \n",
       "len_text, contain_words_75_false, total_8_words...  0.142735  \n",
       "len_text, total_8_words, total_7_ormore_words, ...  0.150232  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bad_column_deleted_2.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las columnas más ruidosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "x_2_train.drop(columns=['len_text', 'contain_words_75_false', 'total_7_ormore_words', 'contain_words_100_false', 'total_common_chars', 'total_7_orless_words'],inplace = True)\n",
    "x_2_test.drop( columns=['len_text', 'contain_words_75_false', 'total_7_ormore_words', 'contain_words_100_false', 'total_common_chars', 'total_7_orless_words'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch con mejores parámetros y mejores features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = LGBMClassifier(random_state = 1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "n_estimators = n_estimators_df.nlargest(4,'accuracy').index.tolist() \n",
    "learning_rate = learning_rate_df.nlargest(4,'accuracy').index.tolist() \n",
    "subsample = subsample_df.nlargest(3,'accuracy').index.tolist()\n",
    "num_leaves = num_leaves_df.nlargest(3,'accuracy').index.tolist()\n",
    "max_depth = max_depth_df.nlargest(3,'accuracy').index.tolist()\n",
    "min_split_gain_leaf = min_split_gain_df.nlargest(3,'accuracy').index.tolist()\n",
    "\n",
    "\n",
    "grid = {\n",
    "               'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'min_split_gain_leaf': min_split_gain_leaf,\n",
    "               'num_leaves': num_leaves,\n",
    "               'subsample': subsample}\n",
    "start = time.time()\n",
    "grid_serch_CV_4 = GridSearchCV(estimator = light_model, param_grid = grid, cv = cv, n_jobs = 2, scoring = 'accuracy')\n",
    "grid_serch_CV_4.fit(x_2_train, y_2_train)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_split_gain_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split93_test_score</th>\n",
       "      <th>split94_test_score</th>\n",
       "      <th>split95_test_score</th>\n",
       "      <th>split96_test_score</th>\n",
       "      <th>split97_test_score</th>\n",
       "      <th>split98_test_score</th>\n",
       "      <th>split99_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.231927</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>0.007535</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.232341</td>\n",
       "      <td>0.022094</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.288215</td>\n",
       "      <td>0.082198</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.244358</td>\n",
       "      <td>0.049801</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.235847</td>\n",
       "      <td>0.021975</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.233520</td>\n",
       "      <td>0.023780</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.233315</td>\n",
       "      <td>0.024634</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.232805</td>\n",
       "      <td>0.022230</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.234880</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.235621</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.794745</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.83087</td>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "330       0.231927      0.021062         0.007535        0.000652   \n",
       "331       0.232341      0.022094         0.007506        0.000624   \n",
       "332       0.288215      0.082198         0.009127        0.004239   \n",
       "366       0.244358      0.049801         0.007718        0.001353   \n",
       "367       0.235847      0.021975         0.007598        0.000880   \n",
       "368       0.233520      0.023780         0.007645        0.000677   \n",
       "402       0.233315      0.024634         0.007691        0.001228   \n",
       "403       0.232805      0.022230         0.007553        0.000708   \n",
       "404       0.234880      0.032439         0.007711        0.000982   \n",
       "438       0.235621      0.027564         0.007701        0.000729   \n",
       "\n",
       "    param_learning_rate param_max_depth param_min_split_gain_leaf  \\\n",
       "330                0.05              28                       0.2   \n",
       "331                0.05              28                       0.2   \n",
       "332                0.05              28                       0.2   \n",
       "366                0.05              28                         0   \n",
       "367                0.05              28                         0   \n",
       "368                0.05              28                         0   \n",
       "402                0.05              28                       0.1   \n",
       "403                0.05              28                       0.1   \n",
       "404                0.05              28                       0.1   \n",
       "438                0.05              32                       0.2   \n",
       "\n",
       "    param_n_estimators param_num_leaves param_subsample  ...  \\\n",
       "330                100               35             0.1  ...   \n",
       "331                100               35             0.2  ...   \n",
       "332                100               35             0.3  ...   \n",
       "366                100               35             0.1  ...   \n",
       "367                100               35             0.2  ...   \n",
       "368                100               35             0.3  ...   \n",
       "402                100               35             0.1  ...   \n",
       "403                100               35             0.2  ...   \n",
       "404                100               35             0.3  ...   \n",
       "438                100               35             0.1  ...   \n",
       "\n",
       "    split93_test_score  split94_test_score  split95_test_score  \\\n",
       "330           0.807882            0.794745            0.802956   \n",
       "331           0.807882            0.794745            0.802956   \n",
       "332           0.807882            0.794745            0.802956   \n",
       "366           0.807882            0.794745            0.802956   \n",
       "367           0.807882            0.794745            0.802956   \n",
       "368           0.807882            0.794745            0.802956   \n",
       "402           0.807882            0.794745            0.802956   \n",
       "403           0.807882            0.794745            0.802956   \n",
       "404           0.807882            0.794745            0.802956   \n",
       "438           0.807882            0.794745            0.802956   \n",
       "\n",
       "     split96_test_score  split97_test_score  split98_test_score  \\\n",
       "330            0.809524            0.779967            0.778325   \n",
       "331            0.809524            0.779967            0.778325   \n",
       "332            0.809524            0.779967            0.778325   \n",
       "366            0.809524            0.779967            0.778325   \n",
       "367            0.809524            0.779967            0.778325   \n",
       "368            0.809524            0.779967            0.778325   \n",
       "402            0.809524            0.779967            0.778325   \n",
       "403            0.809524            0.779967            0.778325   \n",
       "404            0.809524            0.779967            0.778325   \n",
       "438            0.809524            0.779967            0.778325   \n",
       "\n",
       "     split99_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "330             0.83087         0.794647        0.015525                1  \n",
       "331             0.83087         0.794647        0.015525                1  \n",
       "332             0.83087         0.794647        0.015525                1  \n",
       "366             0.83087         0.794647        0.015525                1  \n",
       "367             0.83087         0.794647        0.015525                1  \n",
       "368             0.83087         0.794647        0.015525                1  \n",
       "402             0.83087         0.794647        0.015525                1  \n",
       "403             0.83087         0.794647        0.015525                1  \n",
       "404             0.83087         0.794647        0.015525                1  \n",
       "438             0.83087         0.794647        0.015525                1  \n",
       "\n",
       "[10 rows x 114 columns]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_serch_CV_4.cv_results_).nlargest(10,'mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas haciendo operaciones aritmeticas con cada dos columnas (todas las combinaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_number_columns = get_all_two_columns(x_2_train.select_dtypes(include=['float64','int64']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suma de cada par de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in pair_number_columns:\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    \n",
    "    x_train_plus = x_2_train.copy()\n",
    "    x_train_plus['plus_column'] = x_train_plus[x[0]] + x_train_plus[x[1]]\n",
    "    \n",
    "    n_scores = cross_val_score(light_model, x_train_plus, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    \n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "\n",
    "results_plus = pd.DataFrame(no_column, index=index_no_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_special_chars, text_best_similarity_keyword</th>\n",
       "      <td>0.793054</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.165460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_orless_words, total_6_orless_words</th>\n",
       "      <td>0.792972</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.163645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_5_ormore_words, text_best_similarity_keyword</th>\n",
       "      <td>0.792890</td>\n",
       "      <td>0.013796</td>\n",
       "      <td>0.161147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_ormore_words, text_best_similarity_keyword</th>\n",
       "      <td>0.792824</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>0.174094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_special_chars, total_3_ormore_words</th>\n",
       "      <td>0.792660</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.156964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_special_chars, total_6_ormore_words</th>\n",
       "      <td>0.792660</td>\n",
       "      <td>0.014999</td>\n",
       "      <td>0.161902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_5_words, ratio_short_big_words</th>\n",
       "      <td>0.792578</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>0.169203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_ormore_words, polarity_text</th>\n",
       "      <td>0.792512</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_ormore_words, text_best_similarity_keyword</th>\n",
       "      <td>0.792447</td>\n",
       "      <td>0.015726</td>\n",
       "      <td>0.168683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_words, total_3_ormore_words</th>\n",
       "      <td>0.792430</td>\n",
       "      <td>0.015044</td>\n",
       "      <td>0.165958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "total_special_chars, text_best_similarity_keyword   0.793054  0.015392   \n",
       "total_3_orless_words, total_6_orless_words          0.792972  0.013598   \n",
       "total_5_ormore_words, text_best_similarity_keyword  0.792890  0.013796   \n",
       "total_3_ormore_words, text_best_similarity_keyword  0.792824  0.014866   \n",
       "total_special_chars, total_3_ormore_words           0.792660  0.014075   \n",
       "total_special_chars, total_6_ormore_words           0.792660  0.014999   \n",
       "total_5_words, ratio_short_big_words                0.792578  0.016346   \n",
       "total_8_ormore_words, polarity_text                 0.792512  0.015875   \n",
       "total_8_ormore_words, text_best_similarity_keyword  0.792447  0.015726   \n",
       "total_3_words, total_3_ormore_words                 0.792430  0.015044   \n",
       "\n",
       "                                                        time  \n",
       "total_special_chars, text_best_similarity_keyword   0.165460  \n",
       "total_3_orless_words, total_6_orless_words          0.163645  \n",
       "total_5_ormore_words, text_best_similarity_keyword  0.161147  \n",
       "total_3_ormore_words, text_best_similarity_keyword  0.174094  \n",
       "total_special_chars, total_3_ormore_words           0.156964  \n",
       "total_special_chars, total_6_ormore_words           0.161902  \n",
       "total_5_words, ratio_short_big_words                0.169203  \n",
       "total_8_ormore_words, polarity_text                 0.163771  \n",
       "total_8_ormore_words, text_best_similarity_keyword  0.168683  \n",
       "total_3_words, total_3_ormore_words                 0.165958  "
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_plus.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resta de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in pair_number_columns:\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    \n",
    "    x_train_minus = x_2_train.copy()\n",
    "    x_train_minus['minus_column_1'] = x_train_minus[x[0]] - x_train_minus[x[1]]\n",
    "    x_train_minus['minus_column_2'] = x_train_minus[x[1]] - x_train_minus[x[0]]\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train_minus, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    \n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "\n",
    "results_minus = pd.DataFrame(no_column, index=index_no_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_numbers_chars, total_special_chars</th>\n",
       "      <td>0.792578</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.159710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_words, text_best_similarity_keyword</th>\n",
       "      <td>0.792496</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>0.244192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_ormore_words, text_best_similarity_keyword</th>\n",
       "      <td>0.792479</td>\n",
       "      <td>0.015662</td>\n",
       "      <td>0.188715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_similarity_keyword, ratio_short_big_words</th>\n",
       "      <td>0.792430</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.184998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_numbers_chars, stopword_count</th>\n",
       "      <td>0.792397</td>\n",
       "      <td>0.014124</td>\n",
       "      <td>0.167090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_words, total_8_ormore_words</th>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.165955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_words, total_8_orless_words</th>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.171366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_special_chars, total_3_words</th>\n",
       "      <td>0.792348</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0.221376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_orless_words, total_6_orless_words</th>\n",
       "      <td>0.792315</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>0.168562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_upper_chars, total_8_orless_words</th>\n",
       "      <td>0.792266</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.164760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "total_numbers_chars, total_special_chars            0.792578  0.015321   \n",
       "total_8_words, text_best_similarity_keyword         0.792496  0.014767   \n",
       "total_3_ormore_words, text_best_similarity_keyword  0.792479  0.015662   \n",
       "text_similarity_keyword, ratio_short_big_words      0.792430  0.014368   \n",
       "total_numbers_chars, stopword_count                 0.792397  0.014124   \n",
       "total_words, total_8_ormore_words                   0.792348  0.014741   \n",
       "total_8_words, total_8_orless_words                 0.792348  0.014741   \n",
       "total_special_chars, total_3_words                  0.792348  0.015492   \n",
       "total_3_orless_words, total_6_orless_words          0.792315  0.016238   \n",
       "total_upper_chars, total_8_orless_words             0.792266  0.015102   \n",
       "\n",
       "                                                        time  \n",
       "total_numbers_chars, total_special_chars            0.159710  \n",
       "total_8_words, text_best_similarity_keyword         0.244192  \n",
       "total_3_ormore_words, text_best_similarity_keyword  0.188715  \n",
       "text_similarity_keyword, ratio_short_big_words      0.184998  \n",
       "total_numbers_chars, stopword_count                 0.167090  \n",
       "total_words, total_8_ormore_words                   0.165955  \n",
       "total_8_words, total_8_orless_words                 0.171366  \n",
       "total_special_chars, total_3_words                  0.221376  \n",
       "total_3_orless_words, total_6_orless_words          0.168562  \n",
       "total_upper_chars, total_8_orless_words             0.164760  "
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_minus.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplicación de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in pair_number_columns:\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    \n",
    "    x_train_multi = x_2_train.copy()\n",
    "    x_train_multi['multi_column'] = x_train_multi[x[0]] * x_train_multi[x[1]]\n",
    "    \n",
    "    n_scores = cross_val_score(light_model, x_train_multi, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    \n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "\n",
    "results_multi = pd.DataFrame(no_column, index=index_no_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_special_chars, ratio_short_big_words</th>\n",
       "      <td>0.792709</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.252796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_words_location_cero_default, ratio_short_big_words</th>\n",
       "      <td>0.792660</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.190612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopword_count, text_similarity_keyword</th>\n",
       "      <td>0.792594</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.193418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_words, total_6_ormore_words</th>\n",
       "      <td>0.792578</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.187071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_numbers_chars, len_location_cero_default</th>\n",
       "      <td>0.792545</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.176167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_orless_words, total_6_orless_words</th>\n",
       "      <td>0.792512</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.200776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_words, polarity_text</th>\n",
       "      <td>0.792496</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>0.213749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_orless_words, polarity_text</th>\n",
       "      <td>0.792463</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>0.205782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_5_ormore_words, polarity_text</th>\n",
       "      <td>0.792463</td>\n",
       "      <td>0.014418</td>\n",
       "      <td>0.187454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_ormore_words, polarity_text</th>\n",
       "      <td>0.792447</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.187649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "total_special_chars, ratio_short_big_words          0.792709  0.014989   \n",
       "total_words_location_cero_default, ratio_short_...  0.792660  0.014851   \n",
       "stopword_count, text_similarity_keyword             0.792594  0.013323   \n",
       "total_6_words, total_6_ormore_words                 0.792578  0.014320   \n",
       "total_numbers_chars, len_location_cero_default      0.792545  0.014523   \n",
       "total_3_orless_words, total_6_orless_words          0.792512  0.014187   \n",
       "total_words, polarity_text                          0.792496  0.014928   \n",
       "total_8_orless_words, polarity_text                 0.792463  0.014541   \n",
       "total_5_ormore_words, polarity_text                 0.792463  0.014418   \n",
       "total_6_ormore_words, polarity_text                 0.792447  0.013427   \n",
       "\n",
       "                                                        time  \n",
       "total_special_chars, ratio_short_big_words          0.252796  \n",
       "total_words_location_cero_default, ratio_short_...  0.190612  \n",
       "stopword_count, text_similarity_keyword             0.193418  \n",
       "total_6_words, total_6_ormore_words                 0.187071  \n",
       "total_numbers_chars, len_location_cero_default      0.176167  \n",
       "total_3_orless_words, total_6_orless_words          0.200776  \n",
       "total_words, polarity_text                          0.213749  \n",
       "total_8_orless_words, polarity_text                 0.205782  \n",
       "total_5_ormore_words, polarity_text                 0.187454  \n",
       "total_6_ormore_words, polarity_text                 0.187649  "
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_multi.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division entre columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in pair_number_columns:\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    \n",
    "    x_train_div = x_2_train.copy()\n",
    "    x_train_div[x[1]] = x_train_div[x[1]].replace(0,1)\n",
    "    x_train_div['div_column_1'] = x_train_div[x[0]] / x_train_div[x[1]]\n",
    "    \n",
    "    x_train_div = x_2_train.copy()\n",
    "    x_train_div[x[0]] = x_train_div[x[0]].replace(0,1)\n",
    "    x_train_div['div_column_2'] = x_train_div[x[1]] / x_train_div[x[0]]\n",
    "\n",
    "    n_scores = cross_val_score(light_model, x_train_div, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    \n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "\n",
    "results_div = pd.DataFrame(no_column, index=index_no_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_3_ormore_words, total_5_ormore_words</th>\n",
       "      <td>0.793826</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.244083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_numbers_chars, text_best_similarity_keyword</th>\n",
       "      <td>0.792841</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>0.200186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_words, total_3_ormore_words</th>\n",
       "      <td>0.792726</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.171884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_numbers_chars, total_5_orless_words</th>\n",
       "      <td>0.792677</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.168573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_special_chars, total_5_ormore_words</th>\n",
       "      <td>0.792594</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.180655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_location_cero_default, text_similarity_keyword</th>\n",
       "      <td>0.792447</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.209836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_8_orless_words, unique_word_count</th>\n",
       "      <td>0.792397</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.183842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_3_ormore_words, total_8_orless_words</th>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.197747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_6_ormore_words, total_words_location_cero_default</th>\n",
       "      <td>0.792365</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.199793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_numbers_chars, total_8_orless_words</th>\n",
       "      <td>0.792332</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>0.176564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "total_3_ormore_words, total_5_ormore_words          0.793826  0.015274   \n",
       "total_numbers_chars, text_best_similarity_keyword   0.792841  0.014767   \n",
       "total_3_words, total_3_ormore_words                 0.792726  0.013544   \n",
       "total_numbers_chars, total_5_orless_words           0.792677  0.014540   \n",
       "total_special_chars, total_5_ormore_words           0.792594  0.015830   \n",
       "len_location_cero_default, text_similarity_keyword  0.792447  0.014824   \n",
       "total_8_orless_words, unique_word_count             0.792397  0.015476   \n",
       "total_3_ormore_words, total_8_orless_words          0.792381  0.014547   \n",
       "total_6_ormore_words, total_words_location_cero...  0.792365  0.014603   \n",
       "total_numbers_chars, total_8_orless_words           0.792332  0.014951   \n",
       "\n",
       "                                                        time  \n",
       "total_3_ormore_words, total_5_ormore_words          0.244083  \n",
       "total_numbers_chars, text_best_similarity_keyword   0.200186  \n",
       "total_3_words, total_3_ormore_words                 0.171884  \n",
       "total_numbers_chars, total_5_orless_words           0.168573  \n",
       "total_special_chars, total_5_ormore_words           0.180655  \n",
       "len_location_cero_default, text_similarity_keyword  0.209836  \n",
       "total_8_orless_words, unique_word_count             0.183842  \n",
       "total_3_ormore_words, total_8_orless_words          0.197747  \n",
       "total_6_ormore_words, total_words_location_cero...  0.199793  \n",
       "total_numbers_chars, total_8_orless_words           0.176564  "
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_div.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas haciendo operaciones boleanas con cada dos columnas (todas las combinaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_bool_columns = get_all_two_columns(x_2_train.select_dtypes(include=['bool']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "for x in pair_bool_columns:\n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    \n",
    "    x_train_bool = x_2_train.copy()\n",
    "    x_train_bool['and'] = x_train_bool.apply(lambda y: y[x[0]] and y[x[1]],axis=1)\n",
    "    x_train_bool['or'] = x_train_bool.apply(lambda y: y[x[0]] or y[x[1]],axis=1)\n",
    "    x_train_bool['xor'] = x_train_bool.apply(lambda y: ((not y[x[0]]) and y[x[1]]) or (y[x[0]] and (not y[x[1]])),axis=1)\n",
    "    \n",
    "    n_scores = cross_val_score(light_model, x_train_bool, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    \n",
    "    index_no_column.append(\", \".join(x))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "\n",
    "results_bool = pd.DataFrame(no_column, index=index_no_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contain_upper_words, text_contain_keyword_similarity</th>\n",
       "      <td>0.792677</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.170565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_link, text_contain_word_location</th>\n",
       "      <td>0.792644</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.176465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_question, contain_words_100_true</th>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.180199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_90_false, contain_words_75_true</th>\n",
       "      <td>0.792266</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.170793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_contain_keyword_similarity, contain_words_100_true</th>\n",
       "      <td>0.792184</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.168809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_link, contain_words_90_false</th>\n",
       "      <td>0.792102</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>0.187109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_contain_keyword, contain_link</th>\n",
       "      <td>0.792053</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>0.178642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_85_false, contain_words_80_true</th>\n",
       "      <td>0.791970</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>0.169068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_upper_words, contain_words_70_true</th>\n",
       "      <td>0.791954</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.166927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_words_85_false, contain_words_80_false</th>\n",
       "      <td>0.791954</td>\n",
       "      <td>0.013321</td>\n",
       "      <td>0.170306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    accuracy       std  \\\n",
       "contain_upper_words, text_contain_keyword_simil...  0.792677  0.013925   \n",
       "contain_link, text_contain_word_location            0.792644  0.014578   \n",
       "contain_question, contain_words_100_true            0.792381  0.014781   \n",
       "contain_words_90_false, contain_words_75_true       0.792266  0.013714   \n",
       "text_contain_keyword_similarity, contain_words_...  0.792184  0.014861   \n",
       "contain_link, contain_words_90_false                0.792102  0.014546   \n",
       "text_contain_keyword, contain_link                  0.792053  0.014067   \n",
       "contain_words_85_false, contain_words_80_true       0.791970  0.014479   \n",
       "contain_upper_words, contain_words_70_true          0.791954  0.014950   \n",
       "contain_words_85_false, contain_words_80_false      0.791954  0.013321   \n",
       "\n",
       "                                                        time  \n",
       "contain_upper_words, text_contain_keyword_simil...  0.170565  \n",
       "contain_link, text_contain_word_location            0.176465  \n",
       "contain_question, contain_words_100_true            0.180199  \n",
       "contain_words_90_false, contain_words_75_true       0.170793  \n",
       "text_contain_keyword_similarity, contain_words_...  0.168809  \n",
       "contain_link, contain_words_90_false                0.187109  \n",
       "text_contain_keyword, contain_link                  0.178642  \n",
       "contain_words_85_false, contain_words_80_true       0.169068  \n",
       "contain_upper_words, contain_words_70_true          0.166927  \n",
       "contain_words_85_false, contain_words_80_false      0.170306  "
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bool.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se añaden los mejores resultados de las operaciones anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jtorresbaiva/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#sumas\n",
    "x_2_train['total_special_chars_plus_text_best_similarity_keyword'] = x_2_train.total_special_chars + x_2_train.text_best_similarity_keyword\n",
    "x_2_train['total_3_orless_words_plus_total_6_orless_words'] = x_2_train.total_3_orless_words + x_2_train.total_6_orless_words\n",
    "x_2_train['total_5_ormore_words_plus_text_best_similarity_keyword'] = x_2_train.total_5_ormore_words + x_2_train.text_best_similarity_keyword\n",
    "\n",
    "#restas\n",
    "x_2_train['total_numbers_chars_minus_total_special_chars'] = x_2_train.total_numbers_chars - x_2_train.total_special_chars\n",
    "x_2_train['total_special_chars_minus_total_numbers_chars'] = x_2_train.total_special_chars - x_2_train.total_numbers_chars\n",
    "x_2_train['total_8_words_minus_text_best_similarity_keyword'] = x_2_train.total_8_words - x_2_train.text_best_similarity_keyword\n",
    "x_2_train['text_best_similarity_keyword_minus_total_8_words'] = x_2_train.text_best_similarity_keyword - x_2_train.total_8_words\n",
    "\n",
    "#multiplicación\n",
    "x_2_train['total_special_chars_multi_ratio_short_big_words'] = x_2_train.total_special_chars * x_2_train.ratio_short_big_words\n",
    "x_2_train['total_words_location_cero_default_multi_ratio_short_big_words'] = x_2_train.total_words_location_cero_default * x_2_train.ratio_short_big_words\n",
    "x_2_train['stopword_count_multi_text_similarity_keyword'] = x_2_train.stopword_count * x_2_train.text_similarity_keyword\n",
    "\n",
    "#división\n",
    "\n",
    "x_2_train['total_3_ormore_words_div_total_5_ormore_words'] = x_2_train.total_3_ormore_words / x_2_train.total_5_ormore_words.replace(0,1)\n",
    "x_2_train['total_5_ormore_words_div_total_3_ormore_words'] = x_2_train.total_5_ormore_words / x_2_train.total_3_ormore_words.replace(0,1)\n",
    "x_2_train['total_numbers_chars_div_text_best_similarity_keyword'] = x_2_train.total_numbers_chars / x_2_train.text_best_similarity_keyword.replace(0,1)\n",
    "x_2_train['text_best_similarity_keyword_div_total_numbers_chars'] = x_2_train.text_best_similarity_keyword / x_2_train.total_numbers_chars.replace(0,1)\n",
    "\n",
    "#operaciones boleanas\n",
    "x_2_train['contain_upper_words_and_text_contain_keyword_similarity'] = x_2_train.apply(lambda y: y.contain_upper_words and y.text_contain_keyword_similarity,axis=1)\n",
    "x_2_train['contain_upper_words_or_text_contain_keyword_similarity'] = x_2_train.apply(lambda y: y.contain_upper_words or y.text_contain_keyword_similarity,axis=1)\n",
    "x_2_train['contain_upper_words_xor_text_contain_keyword_similarity'] = x_2_train.apply(lambda y: ((not y.contain_upper_words) and y.text_contain_keyword_similarity) or (y.contain_upper_words and (not y.text_contain_keyword_similarity)),axis=1)\n",
    "x_2_train['contain_link_and_text_contain_word_location'] = x_2_train.apply(lambda y: y.contain_link and y.text_contain_word_location,axis=1)\n",
    "x_2_train['contain_link_or_text_contain_word_location'] = x_2_train.apply(lambda y: y.contain_link or y.text_contain_word_location,axis=1)\n",
    "x_2_train['contain_link_xor_text_contain_word_location'] = x_2_train.apply(lambda y: ((not y.contain_link) and y.text_contain_word_location) or (y.contain_link and (not y.text_contain_word_location)),axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "realizamos unas pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794 (std :0.016). Time: 0.42\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "light_model = LGBMClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "n_scores = cross_val_score(light_model, x_2_train, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('Accuracy: %.3f (std :%.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding con con listas de palabras más comunes en tweets verdaderos y falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "word_list_list = [words_100_true, words_100_false, words_90_true, words_90_false, words_85_true, words_85_false, words_80_true, words_80_false, words_75_true, words_75_false, words_70_true, words_70_false]\n",
    "\n",
    "for word_list in word_list_list:\n",
    "    \n",
    "    x_train_one_hot_enc = x_2_train.copy()\n",
    "\n",
    "    for word in word_list:\n",
    "        is_Ascii = True\n",
    "        for c in word:\n",
    "            if ord(c) > 127 or ord(c) < 0:\n",
    "                is_Ascii = False\n",
    "                break\n",
    "        if not is_Ascii:\n",
    "            continue\n",
    "            \n",
    "        x_train_one_hot_enc[word+'_OHE'] = x_train_one_hot_enc.join(tweets.loc[:,'text']).text.transform(lambda y: word.lower() in y.lower())\n",
    "    \n",
    "    start = time.time()\n",
    "    light_model = LGBMClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    \n",
    "    n_scores = cross_val_score(light_model, x_train_one_hot_enc, y_2_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    \n",
    "    index_no_column.append(word_list_list.index(word_list))\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "\n",
    "results_OHE = pd.DataFrame(no_column, index=index_no_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.797126</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.359531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.795928</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>0.285071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795764</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.296392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795632</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.351458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.795304</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>0.410486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.794959</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.325504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.794943</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.355581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794877</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.335005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794647</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.304725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794499</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.374553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       std      time\n",
       "10  0.797126  0.015773  0.359531\n",
       "5   0.795928  0.015288  0.285071\n",
       "1   0.795764  0.015665  0.296392\n",
       "3   0.795632  0.014825  0.351458\n",
       "11  0.795304  0.016501  0.410486\n",
       "8   0.794959  0.015380  0.325504\n",
       "9   0.794943  0.015599  0.355581\n",
       "7   0.794877  0.015206  0.335005\n",
       "2   0.794647  0.015886  0.304725\n",
       "0   0.794499  0.015916  0.374553"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_OHE.nlargest(10,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
