{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dcarrero/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Columns: 5057 entries, keyword to target\n",
      "dtypes: bool(21), float64(5000), int64(31), object(5)\n",
      "memory usage: 292.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_pre_processing_nlp_5000.csv')\n",
    "test = pd.read_csv('data/test_pre_processing_nlp_5000.csv')\n",
    "train.info()\n",
    "\n",
    "submit = test['id'].to_frame()\n",
    "train.drop(labels=['id'], axis=1, inplace=True)\n",
    "test.drop(labels=['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.select_dtypes(include=['float64','int64','bool'])\n",
    "test = test.select_dtypes(include=['float64','int64','bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_cols = ['location', 'len_location_cero_default', \n",
    "#              'len_location_mean_default', 'total_words_location_cero_default',\n",
    "#             'total_words_location_mean_default', 'text']\n",
    "#train.drop(labels=noise_cols, axis=1, inplace=True)\n",
    "#test.drop(labels=noise_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_for_fit(df):\n",
    "    columns_str = ['keyword_grouped', 'keyword', 'text_clean']\n",
    "    \n",
    "    # Encode with LabelEncoder\n",
    "    encoded_cols = df[columns_str]\n",
    "    encoded_cols = encoded_cols.astype('str')\n",
    "    encoded_cols = encoded_cols.apply(LabelEncoder().fit_transform)\n",
    "    encoded_drop = df.drop(columns_str, axis = 1)\n",
    "    encoded_df = pd.concat([encoded_drop, encoded_cols], axis = 1)\n",
    "    # Drop Target column\n",
    "    if 'target' in encoded_df.columns:\n",
    "        encoded_df.drop(axis=1, labels=['target'], inplace=True)\n",
    "\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(axis=1, labels=['target'])  # prepare_df_for_fit(train) \n",
    "test_X = test # prepare_df_for_fit(test) \n",
    "train_Y = train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dcarrero/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/dcarrero/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "sc_transform = scaler.transform(train_X)\n",
    "X = pd.DataFrame(sc_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train_Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6382632319392976\n",
      "CPU times: user 1min 6s, sys: 607 ms, total: 1min 7s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = knn_model.predict(X_test)\n",
    "print(roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = LGBMClassifier(random_state=1)\n",
    "light_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = light_model.predict(X_test)\n",
    "print(roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('knn', knn_model), ('lgbm', light_model)], voting='hard', weights=[1,2])\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "preds = eclf1.predict(X_test)\n",
    "print(roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
