{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente notebook tiene como objetivo generar un nuevo set de datos con nuevos features, particularmente aquellos que fueron generados en el TP1 (y otros adicionales). Para posteriormente ser usado y modificado en uno o más modelos de ML a probar.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from textblob import TextBlob\n",
    "from geopy.geocoders import Nominatim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set de datos original y se elimina la columna id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/train.csv')\n",
    "tweets.drop(columns=['id'],inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword_grouped (categórica): puede corresponder al mismo keyword del tweet o a una parecida (la parecida se obtiene a partir de un agrupamiento de palabras que tienen un ratio superior al 75% según fuzz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['keyword'] = tweets['keyword'].transform(lambda x: x.str.replace(\"%20\", \" \"))\n",
    "\n",
    "def get_keyword_dic(key_list):\n",
    "    key_dic = {}\n",
    "    unique_list = []\n",
    "    for x in key_list:\n",
    "        similarity = 0\n",
    "        value = \"\"\n",
    "        for y in unique_list:\n",
    "            ratio = fuzz.ratio(x,y)\n",
    "            if ratio > similarity:\n",
    "                similarity = ratio\n",
    "                value = y\n",
    "        if similarity > 75:\n",
    "            key_dic[x] = value\n",
    "        else:\n",
    "            key_dic[x] = x\n",
    "            unique_list.append(x)\n",
    "    return key_dic\n",
    "\n",
    "key_grouped = get_keyword_dic(tweets.keyword.dropna().tolist())\n",
    "\n",
    "key_grouped['blazing'] = 'ablaze'\n",
    "key_grouped['bleeding'] = 'blood'\n",
    "key_grouped['buildings on fire'] = 'buildings burning'\n",
    "key_grouped['burning buildings'] = 'buildings burning'\n",
    "key_grouped['burning'] = 'burned'\n",
    "key_grouped['dead'] = 'death'\n",
    "key_grouped['demolition'] = 'demolish'\n",
    "key_grouped['destruction'] = 'destroy'\n",
    "key_grouped['explosion'] = 'explode'\n",
    "key_grouped['flood'] = 'flooding'\n",
    "key_grouped['floods'] = 'flooding'\n",
    "key_grouped['inundated'] = 'inundation'\n",
    "key_grouped['panic'] = 'panicking'\n",
    "key_grouped['rainstorm'] = 'rainstorm'\n",
    "key_grouped['riot'] = 'rioting'\n",
    "key_grouped['screaming'] = 'screamed'\n",
    "key_grouped['snowstorm'] = 'snowstorm'\n",
    "key_grouped['survivors'] = 'survive'\n",
    "key_grouped['traumatised'] = 'trauma'\n",
    "key_grouped['violent storm'] = 'storm'\n",
    "key_grouped['windstorm'] = 'storm'\n",
    "key_grouped['traumatised'] = 'trauma'\n",
    "\n",
    "tweets['keyword_grouped'] = tweets.keyword.transform(lambda x: None if pd.isna(x) else key_grouped[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_contain_keyword (bool): indica si el texto del tweet contiene la keyword (para los casos que no hay keyword entonces es null). Las comparaciones de los strings se hacen convertidas en minúsculas previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serie_contain_other_serie(x,y):\n",
    "    if pd.isna(y):\n",
    "        return None\n",
    "    return y.lower() in x.lower()\n",
    "\n",
    "tweets['text_contain_keyword'] = tweets.apply(lambda x: serie_contain_other_serie(x.text,x.keyword_grouped), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_words (numérica discreta): total de palabras del texto (se considera palabra todo aquello que es separado por un un espacio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['total_words'] = tweets.text.transform(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len_words (numérica discreta): total de caracteres del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['len_text'] = tweets.text.transform(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_upper_chars (numérica discreta): total de caracteres en mayúsculas del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_total(s):\n",
    "    total = 0\n",
    "    for x in s:\n",
    "        y = ord(x)\n",
    "        if y > 90:\n",
    "            continue\n",
    "        if y > 64:\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_upper_chars'] = tweets.text.transform(lambda x: get_upper_total(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_numbers_chars (numérica discreta): total de caracteres numéricos del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_numbers_chars(s):\n",
    "    total = 0\n",
    "    for x in s:\n",
    "        y = ord(x)\n",
    "        if y in range(48,58):\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_numbers_chars'] = tweets.text.transform(lambda x: get_total_numbers_chars(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_special_chars (numérica discreta): total de caracteres especiales del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_chars_total(s):\n",
    "    total = 0\n",
    "    common_esp_chr = [\" \",\".\",\"?\",\",\",\"!\"]\n",
    "    for x in s:\n",
    "        y = ord(x)\n",
    "        if y in range(97,123) or y in range(65,91) or y in range(48,58) or x in common_esp_chr:\n",
    "            continue\n",
    "        total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_special_chars'] = tweets.text.transform(lambda x: get_special_chars_total(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_common_chars (numérica discreta): total de caracteres comunes del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_chars_total(s):\n",
    "    total = 0\n",
    "    common_esp_chr = [\" \",\".\",\"?\",\",\",\"!\"]\n",
    "    for x in s:\n",
    "        if  x in common_esp_chr:\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_common_chars'] = tweets.text.transform(lambda x: get_common_chars_total(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contain_question (bool): contiene preguntas el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['contain_question'] = tweets.text.transform(lambda x: \"?\" in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contain_link (bool): contiene enlaces el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['contain_link'] = tweets.text.transform(lambda x: \"http\" in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contain_hashtag (bool): contiene hashtag el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['contain_hashtag'] = tweets.text.transform(lambda x: \"#\" in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contain_upper_words (bool): contiene palabras escritas totalmente en mayusculas el texto (de al menos 3 caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_upper_words(s):\n",
    "    for x in s.split(\" \"):\n",
    "        if  len(x) > 2 and x.isupper():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "tweets['contain_upper_words'] = tweets.text.transform(lambda x: contain_upper_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_n_words (numérica discreta): total de palabras de n caracteres del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlenght_words_total(n,s):\n",
    "    total = 0\n",
    "    for x in s.split(\" \"):\n",
    "        if  len(x) == n:\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_3_words'] = tweets.text.transform(lambda x: get_nlenght_words_total(3,x))\n",
    "tweets['total_4_words'] = tweets.text.transform(lambda x: get_nlenght_words_total(4,x))\n",
    "tweets['total_5_words'] = tweets.text.transform(lambda x: get_nlenght_words_total(5,x))\n",
    "tweets['total_6_words'] = tweets.text.transform(lambda x: get_nlenght_words_total(6,x))\n",
    "tweets['total_7_words'] = tweets.text.transform(lambda x: get_nlenght_words_total(7,x))\n",
    "tweets['total_8_words'] = tweets.text.transform(lambda x: get_nlenght_words_total(8,x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_n_ormore_words (numérica discreta): total de palabras de al menos n caracteres del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_ormore_lenght_words_total(n,s):\n",
    "    total = 0\n",
    "    for x in s.split(\" \"):\n",
    "        if  len(x) >= n:\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_3_ormore_words'] = tweets.text.transform(lambda x: get_n_ormore_lenght_words_total(3,x))\n",
    "tweets['total_4_ormore_words'] = tweets.text.transform(lambda x: get_n_ormore_lenght_words_total(4,x))\n",
    "tweets['total_5_ormore_words'] = tweets.text.transform(lambda x: get_n_ormore_lenght_words_total(5,x))\n",
    "tweets['total_6_ormore_words'] = tweets.text.transform(lambda x: get_n_ormore_lenght_words_total(6,x))\n",
    "tweets['total_7_ormore_words'] = tweets.text.transform(lambda x: get_n_ormore_lenght_words_total(7,x))\n",
    "tweets['total_8_ormore_words'] = tweets.text.transform(lambda x: get_n_ormore_lenght_words_total(8,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_n_orless_words (numérica discreta): total de palabras no superiores a n caracteres en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_orless_lenght_words_total(n,s):\n",
    "    total = 0\n",
    "    for x in s.split(\" \"):\n",
    "        if  len(x) <= n:\n",
    "            total = total + 1\n",
    "    return total\n",
    "\n",
    "tweets['total_3_orless_words'] = tweets.text.transform(lambda x: get_n_orless_lenght_words_total(3,x))\n",
    "tweets['total_4_orless_words'] = tweets.text.transform(lambda x: get_n_orless_lenght_words_total(4,x))\n",
    "tweets['total_5_orless_words'] = tweets.text.transform(lambda x: get_n_orless_lenght_words_total(5,x))\n",
    "tweets['total_6_orless_words'] = tweets.text.transform(lambda x: get_n_orless_lenght_words_total(6,x))\n",
    "tweets['total_7_orless_words'] = tweets.text.transform(lambda x: get_n_orless_lenght_words_total(7,x))\n",
    "tweets['total_8_orless_words'] = tweets.text.transform(lambda x: get_n_orless_lenght_words_total(8,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subjectivity_text (numérica continua): subjetividad del texto según TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivityText(x):\n",
    "    return TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "tweets['subjectivity_text'] = tweets.text.transform(lambda x: subjectivityText(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polarity_text (numérica continua): polaridad del texto según TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarityText(x):\n",
    "    return TextBlob(x).sentiment.polarity\n",
    "tweets['polarity_text'] = tweets.text.transform(lambda x: polarityText(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stopword_count** (numérica discreta): cantidad de stopwords en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "def stopWordCount(text):\n",
    "    words = word_tokenize(text)\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in stopWords:\n",
    "            count += 1\n",
    "    return count\n",
    "tweets['stopword_count'] = tweets.text.transform(lambda x: stopWordCount(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**unique_word_count** (numérica discreta): Cantidad de palabras únicas en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWordCount(text):\n",
    "    return len(set(text.split(\" \")))\n",
    "tweets['unique_word_count'] = tweets.text.transform(lambda x: uniqueWordCount(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tomar en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"orga_datos\")\n",
    "def getGeoData(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    \n",
    "    l = geolocator.geocode(x, timeout=1,country_codes=[\"US\",\"UC\",\"CA\",\"IN\",\"AU\",\"FR\"])\n",
    "    \n",
    "    if l == None:\n",
    "        return pd.NA\n",
    "    return (l.address, l.latitude, l.longitude)\n",
    "\n",
    "#tweets['address'] = tweets.location.transform(lambda x: getGeoData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 38 columns):\n",
      "keyword                 7552 non-null object\n",
      "location                5080 non-null object\n",
      "text                    7613 non-null object\n",
      "keyword_grouped         7552 non-null object\n",
      "text_contain_keyword    7552 non-null object\n",
      "total_words             7613 non-null int64\n",
      "len_text                7613 non-null int64\n",
      "total_upper_chars       7613 non-null int64\n",
      "total_numbers_chars     7613 non-null int64\n",
      "total_special_chars     7613 non-null int64\n",
      "total_common_chars      7613 non-null int64\n",
      "contain_question        7613 non-null bool\n",
      "contain_link            7613 non-null bool\n",
      "contain_hashtag         7613 non-null bool\n",
      "contain_upper_words     7613 non-null bool\n",
      "total_3_words           7613 non-null int64\n",
      "total_4_words           7613 non-null int64\n",
      "total_5_words           7613 non-null int64\n",
      "total_6_words           7613 non-null int64\n",
      "total_7_words           7613 non-null int64\n",
      "total_8_words           7613 non-null int64\n",
      "total_3_ormore_words    7613 non-null int64\n",
      "total_4_ormore_words    7613 non-null int64\n",
      "total_5_ormore_words    7613 non-null int64\n",
      "total_6_ormore_words    7613 non-null int64\n",
      "total_7_ormore_words    7613 non-null int64\n",
      "total_8_ormore_words    7613 non-null int64\n",
      "total_3_orless_words    7613 non-null int64\n",
      "total_4_orless_words    7613 non-null int64\n",
      "total_5_orless_words    7613 non-null int64\n",
      "total_6_orless_words    7613 non-null int64\n",
      "total_7_orless_words    7613 non-null int64\n",
      "total_8_orless_words    7613 non-null int64\n",
      "subjectivity_text       7613 non-null float64\n",
      "polarity_text           7613 non-null float64\n",
      "stopword_count          7613 non-null int64\n",
      "unique_word_count       7613 non-null int64\n",
      "target                  7613 non-null int64\n",
      "dtypes: bool(4), float64(2), int64(27), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "target = tweets.target\n",
    "tweets.drop(columns=['target'], inplace=True)\n",
    "tweets['target'] = target\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('data/train_pre_processing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
