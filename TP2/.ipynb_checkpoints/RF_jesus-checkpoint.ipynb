{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_start = time.time()\n",
    "\n",
    "tweets = pd.read_csv(\"data/train_pre_processing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas solo con variables num√©ricas y booleanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = tweets.select_dtypes(include=['float64','int64','bool']).iloc[:,:-1],tweets.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con valores por default del RandomForestClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_stimators = 100\n",
    "max_depth = none\n",
    "min_samples_split = 2\n",
    "min_samples_leaf = 1\n",
    "max_leaf_nodes = none \n",
    "max_samples = 1\n",
    "max_features = sqrt(len(x_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.697 (desv:  0.017). Time: 0.69\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "print('ACC: %.3f (desv:  %.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end - start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas descartando una columna (todas las combinaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_columns = {}\n",
    "\n",
    "for x in range(0,30):\n",
    "    column_list = []\n",
    "    for y in range(0,30):\n",
    "        if y != x:\n",
    "            column_list.append(y)\n",
    "    x_train_columns[x] = column_list\n",
    "\n",
    "def get_dic_acc():\n",
    "    results = {}\n",
    "    results['accuracy'] = []\n",
    "    results['std'] = []\n",
    "    results['time'] = []\n",
    "    \n",
    "    return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_column = get_dic_acc()\n",
    "index_no_column = []\n",
    "\n",
    "\n",
    "for x in range(0,30):\n",
    "    start = time.time()\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state=1)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "    x_train_2 = x_train.iloc[:,x_train_columns[x]]\n",
    "    n_scores = cross_val_score(rf_model, x_train_2, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    index_no_column.append(x_train.columns[x])\n",
    "    no_column['accuracy'].append(np.mean(n_scores))\n",
    "    no_column['std'].append(np.std(n_scores))\n",
    "    no_column['time'].append((end - start)/60)\n",
    "\n",
    "pd.DataFrame(no_column, index=index_no_column).nlargest(10,'accuracy')     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "realizo una prueba eliminando aquellas columnas que no disminuyeron el resultado de Accuracy con tres decimales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.694 (desv:  0.016). Time: 0.59\n"
     ]
    }
   ],
   "source": [
    "x_train_2 = x_train.drop(columns=['total_words','total_6_words','total_7_words','total_8_ormore_words']) \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=1)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,random_state=1)\n",
    "\n",
    "n_scores = cross_val_score(rf_model, x_train_2, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "end = time.time()\n",
    "\n",
    "print('ACC: %.3f (desv:  %.3f). Time: %.2f' % (np.mean(n_scores), np.std(n_scores),(end - start)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando el porcentaje de datos en  cada √°rbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.687 (desv:  0.019) with max_samples: 0.100000. Time: 0.20\n",
      "ACC: 0.695 (desv:  0.018) with max_samples: 0.200000. Time: 0.26\n",
      "ACC: 0.698 (desv:  0.017) with max_samples: 0.300000. Time: 0.32\n",
      "ACC: 0.697 (desv:  0.017) with max_samples: 0.400000. Time: 0.37\n",
      "ACC: 0.697 (desv:  0.016) with max_samples: 0.500000. Time: 0.42\n",
      "ACC: 0.697 (desv:  0.017) with max_samples: 0.600000. Time: 0.45\n",
      "ACC: 0.696 (desv:  0.017) with max_samples: 0.700000. Time: 0.49\n",
      "ACC: 0.696 (desv:  0.016) with max_samples: 0.800000. Time: 0.52\n",
      "ACC: 0.697 (desv:  0.016) with max_samples: 0.900000. Time: 0.56\n",
      "Best max_sample: 0\n"
     ]
    }
   ],
   "source": [
    "max_samples_best = 0 \n",
    "max_samples_acc = 0 \n",
    "max_samples_std = 0\n",
    "\n",
    "max_samples_dic = get_dic_acc()\n",
    "index_max_samples = []\n",
    "\n",
    "max_sample = 0.1\n",
    "for x in range(1,10):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_sample)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "    \n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "    \n",
    "    index_max_samples.append(max_sample)\n",
    "    max_samples_dic['accuracy'].append(mean)\n",
    "    max_samples_dic['std'].append(np.std(std)\n",
    "    max_samples_dic['time'].append((end - start)/60)\n",
    "                                \n",
    "    if (mean > max_samples_acc) or (mean == max_samples_acc and std < max_samples_std): \n",
    "        max_samples_best = max_sample\n",
    "        max_samples_acc = mean\n",
    "        max_samples_std = std\n",
    "    \n",
    "    \n",
    "    max_sample = max_sample + 0.1\n",
    "    \n",
    "print(\"Best max_sample: %.1f\" % (max_samples_best))\n",
    "\n",
    "pd.DataFrame(max_samples_dic, index=index_max_samples).nlargest(10,'accuracy')     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando el m√°ximo de fatures por  cada √°rbol con el mejor max_samples anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.698 (desv:  0.017) with max_features: 1. Time: 0.21\n",
      "ACC: 0.696 (desv:  0.017) with max_features: 3. Time: 0.26\n",
      "ACC: 0.698 (desv:  0.017) with max_features: 5. Time: 0.32\n",
      "ACC: 0.696 (desv:  0.017) with max_features: 7. Time: 0.37\n",
      "ACC: 0.697 (desv:  0.017) with max_features: 9. Time: 0.41\n",
      "ACC: 0.698 (desv:  0.018) with max_features: 11. Time: 0.47\n",
      "ACC: 0.697 (desv:  0.018) with max_features: 13. Time: 0.50\n",
      "ACC: 0.697 (desv:  0.017) with max_features: 15. Time: 0.56\n",
      "ACC: 0.698 (desv:  0.018) with max_features: 17. Time: 0.61\n",
      "ACC: 0.698 (desv:  0.016) with max_features: 19. Time: 0.65\n",
      "ACC: 0.697 (desv:  0.018) with max_features: 21. Time: 0.70\n",
      "ACC: 0.698 (desv:  0.018) with max_features: 23. Time: 0.76\n",
      "ACC: 0.699 (desv:  0.019) with max_features: 25. Time: 0.87\n",
      "ACC: 0.698 (desv:  0.017) with max_features: 27. Time: 0.83\n",
      "ACC: 0.698 (desv:  0.016) with max_features: 29. Time: 0.85\n",
      "Best max_features: 25\n"
     ]
    }
   ],
   "source": [
    "max_features_best = 0\n",
    "max_features_acc = 0\n",
    "max_features_std = 0\n",
    "\n",
    "max_features_dic = get_dic_acc()\n",
    "index_max_features = []\n",
    "\n",
    "for x in range(1,len(x_train.columns)+1,2):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_samples_best, max_features= x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "    \n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "    \n",
    "    index_max_features.append(x)\n",
    "    max_features_dic['accuracy'].append(mean)\n",
    "    max_features_dic['std'].append(np.std(std)\n",
    "    max_features_dic['time'].append((end - start)/60)\n",
    "\n",
    "    \n",
    "    if (mean > max_features_acc) or (mean == max_features_acc and std < max_features_std): \n",
    "        max_features_best = x\n",
    "        max_features_acc = mean\n",
    "        max_features_std = std\n",
    "    \n",
    "print(\"Best max_features: %d\" % (max_features_best))\n",
    "\n",
    "pd.DataFrame(max_features_dic, index=index_max_features).nlargest(10,'accuracy')     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando cantidad de √°rboles con los mejores par√°metros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.700 (desv:  0.018) with n_estimators: 200. Time: 1.49\n",
      "ACC: 0.701 (desv:  0.017) with n_estimators: 300. Time: 2.37\n",
      "ACC: 0.702 (desv:  0.017) with n_estimators: 400. Time: 3.20\n",
      "ACC: 0.702 (desv:  0.017) with n_estimators: 500. Time: 4.10\n",
      "ACC: 0.702 (desv:  0.017) with n_estimators: 600. Time: 4.71\n",
      "ACC: 0.702 (desv:  0.016) with n_estimators: 700. Time: 5.18\n",
      "ACC: 0.701 (desv:  0.017) with n_estimators: 800. Time: 6.39\n",
      "ACC: 0.701 (desv:  0.017) with n_estimators: 900. Time: 7.04\n",
      "ACC: 0.701 (desv:  0.017) with n_estimators: 1000. Time: 7.43\n",
      "Best n_estimators: 600\n"
     ]
    }
   ],
   "source": [
    "n_estimators_best = 0\n",
    "n_estimators_acc = 0\n",
    "n_estimators_std = 0\n",
    "\n",
    "n_estimators_dic = get_dic_acc()\n",
    "index_n_estimators = []\n",
    "\n",
    "for x in range(200,1001,100):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_samples_best, max_features= max_features_best, n_estimators = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_n_estimators.append(x)\n",
    "    n_estimators_dic['accuracy'].append(mean)\n",
    "    n_estimators_dic['std'].append(np.std(std)\n",
    "    n_estimators_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > n_estimators_acc) or (mean == n_estimators_acc and std < n_estimators_std): \n",
    "        n_estimators_best = x\n",
    "        n_estimators_acc = mean\n",
    "        n_estimators_std = std\n",
    " \n",
    "    \n",
    "print(\"Best n_estimators: %d\" % (n_estimators_best))\n",
    "\n",
    "pd.DataFrame(n_estimators_dic, index=index_n_estimators).nlargest(10,'accuracy')     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando max_depth con los mejores par√°metros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.678 (desv:  0.019) with max_depth: 4. Time: 1.87\n",
      "ACC: 0.691 (desv:  0.018) with max_depth: 8. Time: 3.15\n",
      "ACC: 0.699 (desv:  0.018) with max_depth: 12. Time: 3.98\n",
      "ACC: 0.701 (desv:  0.017) with max_depth: 16. Time: 4.33\n",
      "ACC: 0.701 (desv:  0.017) with max_depth: 20. Time: 4.43\n",
      "ACC: 0.702 (desv:  0.016) with max_depth: 24. Time: 4.49\n",
      "ACC: 0.702 (desv:  0.017) with max_depth: 28. Time: 4.45\n",
      "ACC: 0.702 (desv:  0.017) with max_depth: 32. Time: 4.56\n",
      "ACC: 0.702 (desv:  0.017) with max_depth: 36. Time: 4.76\n",
      "ACC: 0.702 (desv:  0.017) with max_depth: 40. Time: 4.87\n",
      "Best max_depth: 36\n"
     ]
    }
   ],
   "source": [
    "max_depth_best = 0\n",
    "max_depth_acc = 0\n",
    "max_depth_std = 0\n",
    "\n",
    "max_depth_dic = get_dic_acc()\n",
    "index_max_depth = []\n",
    "\n",
    "for x in range(4,41,4):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_samples_best, max_features= max_features_best, n_estimators = n_estimators_best,max_depth = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_max_depth.append(x)\n",
    "    max_depth_dic['accuracy'].append(mean)\n",
    "    max_depth_dic['std'].append(np.std(std)\n",
    "    max_depth_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > max_depth_acc) or (mean == max_depth_acc and std < max_depth_std): \n",
    "        max_depth_best = x\n",
    "        max_depth_acc = mean\n",
    "        max_depth_std = std\n",
    "    \n",
    "print(\"Best max_depth: %d\" % (max_depth_best))\n",
    "\n",
    "pd.DataFrame(max_depth_dic, index=index_max_depth).nlargest(10,'accuracy') \n",
    "                                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando min_samples_split con lo mejores par√°metros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.701 (desv:  0.016) with min_samples_split: 4. Time: 5.13\n",
      "ACC: 0.700 (desv:  0.017) with min_samples_split: 8. Time: 4.82\n",
      "ACC: 0.698 (desv:  0.017) with min_samples_split: 12. Time: 4.46\n",
      "ACC: 0.697 (desv:  0.016) with min_samples_split: 16. Time: 4.18\n",
      "ACC: 0.696 (desv:  0.017) with min_samples_split: 20. Time: 3.92\n",
      "ACC: 0.695 (desv:  0.017) with min_samples_split: 24. Time: 3.77\n",
      "ACC: 0.694 (desv:  0.017) with min_samples_split: 28. Time: 3.67\n",
      "ACC: 0.693 (desv:  0.017) with min_samples_split: 32. Time: 3.60\n",
      "ACC: 0.693 (desv:  0.018) with min_samples_split: 36. Time: 3.50\n",
      "ACC: 0.692 (desv:  0.017) with min_samples_split: 40. Time: 3.45\n",
      "Best min_samples_split: 4\n"
     ]
    }
   ],
   "source": [
    "min_samples_split_best = 0\n",
    "min_samples_split_acc = 0\n",
    "min_samples_split_std = 0\n",
    "\n",
    "min_samples_split_dic = get_dic_acc()\n",
    "index_min_samples_split = []\n",
    "\n",
    "for x in range(4,41,4):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_samples_best, max_features= max_features_best, n_estimators = n_estimators_best,max_depth = max_depth_best,min_samples_split = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_min_samples_split.append(x)\n",
    "    min_samples_split_dic['accuracy'].append(mean)\n",
    "    min_samples_split_dic['std'].append(np.std(std)\n",
    "    min_samples_split_dic['time'].append((end - start)/60)\n",
    "    \n",
    "    if (mean > min_samples_split_acc) or (mean == min_samples_split_acc and std < min_samples_split_std): \n",
    "        min_samples_split_best = x\n",
    "        min_samples_split_acc = mean\n",
    "        min_samples_split_std = std\n",
    "    \n",
    "print(\"Best min_samples_split: %d\" % (min_samples_split_best))\n",
    "\n",
    "pd.DataFrame(min_samples_split_dic, index=index_min_samples_split).nlargest(10,'accuracy') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando min_samples_leaf con los mejores parametros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.701 (desv:  0.016) with min_samples_leaf: 1. Time: 4.89\n",
      "ACC: 0.698 (desv:  0.017) with min_samples_leaf: 3. Time: 4.35\n",
      "ACC: 0.695 (desv:  0.016) with min_samples_leaf: 5. Time: 3.94\n",
      "ACC: 0.694 (desv:  0.017) with min_samples_leaf: 7. Time: 3.48\n",
      "ACC: 0.692 (desv:  0.018) with min_samples_leaf: 9. Time: 3.31\n",
      "ACC: 0.691 (desv:  0.018) with min_samples_leaf: 11. Time: 3.12\n",
      "ACC: 0.691 (desv:  0.018) with min_samples_leaf: 13. Time: 3.03\n",
      "ACC: 0.689 (desv:  0.017) with min_samples_leaf: 15. Time: 2.95\n",
      "ACC: 0.689 (desv:  0.017) with min_samples_leaf: 17. Time: 2.80\n",
      "ACC: 0.688 (desv:  0.018) with min_samples_leaf: 19. Time: 2.75\n",
      "Best min_samples_leaf: 1\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf_best = 0\n",
    "min_samples_leaf_acc = 0\n",
    "min_samples_leaf_std = 0\n",
    "\n",
    "min_samples_leaf_dic = get_dic_acc()\n",
    "index_min_samples_leaf = []\n",
    "\n",
    "for x in range(1,21,2):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_samples_best, max_features= max_features_best, n_estimators = n_estimators_best,max_depth = max_depth_best,min_samples_split = min_samples_split_best,min_samples_leaf = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_min_samples_leaf.append(x)\n",
    "    min_samples_leaf_dic['accuracy'].append(mean)\n",
    "    min_samples_leaf_dic['std'].append(np.std(std)\n",
    "    min_samples_leaf_dic['time'].append((end - start)/60)\n",
    "                                        \n",
    "    if (mean > min_samples_leaf_acc) or (mean == min_samples_leaf_acc and std < min_samples_leaf_std): \n",
    "        min_samples_leaf_best = x\n",
    "        min_samples_leaf_acc = mean\n",
    "        min_samples_leaf_std = std\n",
    "    \n",
    "print(\"Best min_samples_leaf: %d\" % (min_samples_leaf_best))\n",
    "\n",
    "pd.DataFrame(min_samples_leaf_dic, index=index_min_samples_leaf).nlargest(10,'accuracy') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas variando max_leaf_nodes con los mejores parametros anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.642 (desv:  0.020) with max_leaf_nodes: 2. Time: 1.26\n",
      "ACC: 0.700 (desv:  0.018) with max_leaf_nodes: 202. Time: 4.16\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 402. Time: 4.52\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 602. Time: 4.59\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 802. Time: 4.52\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 1002. Time: 4.66\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 1202. Time: 4.70\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 1402. Time: 4.95\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 1602. Time: 4.87\n",
      "ACC: 0.701 (desv:  0.017) with max_leaf_nodes: 1802. Time: 4.58\n",
      "Best max_leaf_nodes: 402\n"
     ]
    }
   ],
   "source": [
    "max_leaf_nodes_best = 0\n",
    "max_leaf_nodes_acc = 0\n",
    "max_leaf_nodes_std = 0\n",
    "\n",
    "max_leaf_nodes_dic = get_dic_acc()\n",
    "index_max_leaf_nodes = []\n",
    "\n",
    "for x in range(2,2001,200):\n",
    "    start = time.time()\n",
    "    rf_model = RandomForestClassifier(random_state=1,max_samples = max_samples_best, max_features= max_features_best, n_estimators = n_estimators_best,max_depth = max_depth_best,min_samples_split = min_samples_split_best,min_samples_leaf = min_samples_leaf_best, max_leaf_nodes = x)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "\n",
    "    n_scores = cross_val_score(rf_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    mean = np.mean(n_scores)\n",
    "    std = np.std(n_scores)\n",
    "    end = time.time()\n",
    "\n",
    "    index_max_leaf_nodes.append(x)\n",
    "    max_leaf_nodes_dic['accuracy'].append(mean)\n",
    "    max_leaf_nodes_dic['std'].append(np.std(std)\n",
    "    max_leaf_nodes_dic['time'].append((end - start)/60)\n",
    "                                        \n",
    "    if (mean > max_leaf_nodes_acc) or (mean == max_leaf_nodes_acc and std < max_leaf_nodes_std): \n",
    "        max_leaf_nodes_best = x\n",
    "        max_leaf_nodes_acc = mean\n",
    "        max_leaf_nodes_std = std\n",
    "    \n",
    "print(\"Best max_leaf_nodes: %d\" % (max_leaf_nodes_best))\n",
    "\n",
    "pd.DataFrame(max_leaf_nodes_dic, index=index_max_leaf_nodes).nlargest(10,'accuracy') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid searh usando valores cercanos a los mejores par√°metros encontrados anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "n_estimators = [200,400]\n",
    "max_features = [5, 25]\n",
    "criterion = ['gini','entropy']\n",
    "max_depth = [16,24,36]\n",
    "min_samples_split = [4,8,12]\n",
    "min_samples_leaf = [1,7,17]\n",
    "max_leaf_nodes = [2,200,400]\n",
    "max_samples = [max_samples_best]\n",
    "\n",
    "grid = {'criterion' : criterion,\n",
    "               'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_leaf_nodes': max_leaf_nodes,'max_samples': max_samples_best}\n",
    "start = time.time()\n",
    "grid_serch_CV = GridSearchCV(estimator = rf_model, param_grid = grid, cv = 10, n_jobs = 2, scoring = 'accuracy')\n",
    "grid_serch_CV.fit(x_train, y_train)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.340344</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.660099</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.638752</td>\n",
       "      <td>0.626273</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779705</td>\n",
       "      <td>0.069559</td>\n",
       "      <td>0.048056</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.612479</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.637110</td>\n",
       "      <td>0.625944</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.373120</td>\n",
       "      <td>0.047236</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.660099</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.638752</td>\n",
       "      <td>0.626273</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.728910</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.612479</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.637110</td>\n",
       "      <td>0.625944</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.378601</td>\n",
       "      <td>0.014021</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.607553</td>\n",
       "      <td>0.660099</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.638752</td>\n",
       "      <td>0.626273</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>3.005875</td>\n",
       "      <td>0.113856</td>\n",
       "      <td>0.054464</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>entropy</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.688013</td>\n",
       "      <td>0.709360</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.691790</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1.483289</td>\n",
       "      <td>0.034360</td>\n",
       "      <td>0.027314</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>entropy</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697865</td>\n",
       "      <td>0.656814</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.692939</td>\n",
       "      <td>0.689491</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2.952451</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>0.050602</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>entropy</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.688013</td>\n",
       "      <td>0.709360</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.691790</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1.483891</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>entropy</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697865</td>\n",
       "      <td>0.656814</td>\n",
       "      <td>0.681445</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.706076</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.692939</td>\n",
       "      <td>0.689491</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2.967249</td>\n",
       "      <td>0.020376</td>\n",
       "      <td>0.049715</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>entropy</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.688013</td>\n",
       "      <td>0.709360</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.704433</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.691790</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.340344      0.011840         0.017577        0.000428   \n",
       "1         0.779705      0.069559         0.048056        0.011748   \n",
       "2         0.373120      0.047236         0.020036        0.003239   \n",
       "3         0.728910      0.021886         0.038561        0.003933   \n",
       "4         0.378601      0.014021         0.021211        0.002252   \n",
       "..             ...           ...              ...             ...   \n",
       "643       3.005875      0.113856         0.054464        0.007330   \n",
       "644       1.483289      0.034360         0.027314        0.002300   \n",
       "645       2.952451      0.031027         0.050602        0.002396   \n",
       "646       1.483891      0.016682         0.026879        0.002616   \n",
       "647       2.967249      0.020376         0.049715        0.001431   \n",
       "\n",
       "    param_criterion param_max_depth param_max_features param_max_leaf_nodes  \\\n",
       "0              gini              16                  5                    2   \n",
       "1              gini              16                  5                    2   \n",
       "2              gini              16                  5                    2   \n",
       "3              gini              16                  5                    2   \n",
       "4              gini              16                  5                    2   \n",
       "..              ...             ...                ...                  ...   \n",
       "643         entropy              36                 25                  400   \n",
       "644         entropy              36                 25                  400   \n",
       "645         entropy              36                 25                  400   \n",
       "646         entropy              36                 25                  400   \n",
       "647         entropy              36                 25                  400   \n",
       "\n",
       "    param_max_samples param_min_samples_leaf  ... split3_test_score  \\\n",
       "0                 0.3                      1  ...          0.607553   \n",
       "1                 0.3                      1  ...          0.607553   \n",
       "2                 0.3                      1  ...          0.607553   \n",
       "3                 0.3                      1  ...          0.607553   \n",
       "4                 0.3                      1  ...          0.607553   \n",
       "..                ...                    ...  ...               ...   \n",
       "643               0.3                     17  ...          0.696223   \n",
       "644               0.3                     17  ...          0.697865   \n",
       "645               0.3                     17  ...          0.696223   \n",
       "646               0.3                     17  ...          0.697865   \n",
       "647               0.3                     17  ...          0.696223   \n",
       "\n",
       "    split4_test_score split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.586207          0.607553           0.660099           0.628900   \n",
       "1            0.591133          0.612479           0.658456           0.632184   \n",
       "2            0.586207          0.607553           0.660099           0.628900   \n",
       "3            0.591133          0.612479           0.658456           0.632184   \n",
       "4            0.586207          0.607553           0.660099           0.628900   \n",
       "..                ...               ...                ...                ...   \n",
       "643          0.673235          0.688013           0.709360           0.701149   \n",
       "644          0.656814          0.681445           0.701149           0.706076   \n",
       "645          0.673235          0.688013           0.709360           0.701149   \n",
       "646          0.656814          0.681445           0.701149           0.706076   \n",
       "647          0.673235          0.688013           0.709360           0.701149   \n",
       "\n",
       "     split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.628900           0.638752         0.626273        0.020113   \n",
       "1             0.632184           0.637110         0.625944        0.017437   \n",
       "2             0.628900           0.638752         0.626273        0.020113   \n",
       "3             0.632184           0.637110         0.625944        0.017437   \n",
       "4             0.628900           0.638752         0.626273        0.020113   \n",
       "..                 ...                ...              ...             ...   \n",
       "643           0.704433           0.701149         0.691790        0.014779   \n",
       "644           0.704433           0.692939         0.689491        0.015516   \n",
       "645           0.704433           0.701149         0.691790        0.014779   \n",
       "646           0.704433           0.692939         0.689491        0.015516   \n",
       "647           0.704433           0.701149         0.691790        0.014779   \n",
       "\n",
       "     rank_test_score  \n",
       "0                568  \n",
       "1                622  \n",
       "2                568  \n",
       "3                622  \n",
       "4                568  \n",
       "..               ...  \n",
       "643              259  \n",
       "644              325  \n",
       "645              259  \n",
       "646              325  \n",
       "647              259  \n",
       "\n",
       "[648 rows x 26 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_serch_CV.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generaci√≥n de features a partir del uso de CV mean encoding sobre keyword_grouped, city and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"orga_datos\")\n",
    "def getGeoData(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    try:\n",
    "        l = geolocator.geocode(x, timeout=20)\n",
    "    except:\n",
    "        return pd.NA\n",
    "    \n",
    "    if l == None:\n",
    "        return pd.NA\n",
    "    return (l.address, l.latitude, l.longitude)\n",
    "\n",
    "tweets['address'] = tweets.location.transform(lambda x: getGeoData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3996     0.611111\n",
       "2431     0.597222\n",
       "1130     0.478873\n",
       "1533       0.4375\n",
       "5897         0.75\n",
       "6554     0.382979\n",
       "2326      0.21875\n",
       "3045     0.789474\n",
       "1029    0.0660377\n",
       "3320     0.756757\n",
       "dtype: object"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_column_with_cv_mean_encoding(column_name):\n",
    "    total_true = tweets.groupby(column_name).target.transform(sum)\n",
    "    dic_total = tweets.groupby(column_name)[column_name].count().to_dict()\n",
    "    total = tweets[column_name].transform(lambda x: pd.NA if pd.isna(x) else dic_total[x])\n",
    "\n",
    "    return (total_true - tweets.target) / (total - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas incluyendo nuevos features con hiperpar√°metros por default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2, y_2 = tweets.select_dtypes(include=['float64','int64','bool']).iloc[:,:-1],tweets.iloc[:,-1]\n",
    "x_train_2, x_test_2, y_train, y_test = train_test_split(x_2, y_2, test_size=0.2, random_state=123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
