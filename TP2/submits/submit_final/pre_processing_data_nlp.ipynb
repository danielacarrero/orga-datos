{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "pre_processing_data_nlpVF2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3gi7ELAE65Fg",
        "5fAcFNKN65Gw",
        "Crl0lvNy65G2",
        "TvpJDPgG65G8",
        "kEXDBN_H65Hb",
        "mgnQ8ZvU65IB"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-oT6cML65FQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "85e66d80-35ec-4aae-8f39-469d85ec84be"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from spellchecker import SpellChecker\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import re\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ0Aggn_65Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('data/train_pre_processing.csv')\n",
        "test = pd.read_csv('data/test_pre_processing.csv')\n",
        "train_ID = pd.read_csv('data/train.csv') #para agregar el id a train que no posee\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gi7ELAE65Fg",
        "colab_type": "text"
      },
      "source": [
        "## Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SabIYeS65Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_url(text):\n",
        "    text = re.compile(r'https?://\\S+|www\\.\\S+').sub(r' ', text)\n",
        "    text = re.compile(r'http\\S+').sub(r'', text)\n",
        "    text = re.compile(r'www\\S+').sub(r'', text)\n",
        "    text = re.compile(r'pic.twitter.com\\S+').sub(r' ', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He9-q1g-65Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    html = re.compile(r'<.*?>')\n",
        "    return html.sub(r' ',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysd5N3cp65Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxZlfH8o65F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    table=str.maketrans('','',string.punctuation)\n",
        "    return text.translate(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKrV_HiR65F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    words = [w for w in words if not w in STOPWORDS]\n",
        "    return ' '.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CXjnjXS65GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spell = SpellChecker()\n",
        "def spellcheck(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eByEAkdV65GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_non_ascii(text):\n",
        "    return re.compile(r'[^A-Za-z0-9\\.\\'!\\?,\\$]').sub(r' ', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvNRskOU65GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_spaces(text):\n",
        "    # Reemplazar multiples espacios en uno\n",
        "    return re.sub('\\s{2,}', ' ', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD23V3e065GY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"â‚¬\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "def convert_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
        "\n",
        "def convert_abbrev_in_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [convert_abbrev(word) for word in tokens]\n",
        "    text = ' '.join(tokens)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi_tF_ed65Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = remove_url(text)\n",
        "    text = remove_html(text)\n",
        "    text = remove_emoji(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = remove_stopwords(text)\n",
        "    #text = clean_non_ascii(text)\n",
        "    #text = clean_spaces(text)\n",
        "    #text = convert_abbrev_in_text(text)\n",
        "    #text = spellcheck(text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl2b6XX_65Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text_clean'] = train.text.transform(lambda x: clean_text(str(x)))\n",
        "test['text_clean'] = test.text.transform(lambda x: clean_text(str(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viv9Elda65Gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cea8e55-f2f7-4e45-ef85-42ab95b6fa38"
      },
      "source": [
        "train[['text','text_clean']].sample(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2591</th>\n",
              "      <td>Black Eye 9: A space battle occurred at Star O784 involving 3 fleets totaling 3942 ships with 14 destroyed</td>\n",
              "      <td>black eye 9 space battle occurred star o784 involving 3 fleets totaling 3942 ships 14 destroyed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>Salvation Army hosts rally to reconnect fathers with children: The Salvation Army is hosting a back to school rallyÂ‰Ã›_ http://t.co/rDjpor3AZg</td>\n",
              "      <td>salvation army hosts rally reconnect fathers children salvation army hosting back school rallyÂ‰Ã»</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                               text                                                                                        text_clean\n",
              "2591  Black Eye 9: A space battle occurred at Star O784 involving 3 fleets totaling 3942 ships with 14 destroyed                                     black eye 9 space battle occurred star o784 involving 3 fleets totaling 3942 ships 14 destroyed \n",
              "354   Salvation Army hosts rally to reconnect fathers with children: The Salvation Army is hosting a back to school rallyÂ‰Ã›_ http://t.co/rDjpor3AZg  salvation army hosts rally reconnect fathers children salvation army hosting back school rallyÂ‰Ã»"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fAcFNKN65Gw",
        "colab_type": "text"
      },
      "source": [
        "## Mean Word Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CVAr8hI65Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['mean_word_len'] = train.text.transform(lambda x: np.mean([len(word) for word in str(x).split()]))\n",
        "test['mean_word_len'] = test.text.transform(lambda x: np.mean([len(word) for word in str(x).split()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crl0lvNy65G2",
        "colab_type": "text"
      },
      "source": [
        "## N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDYTRrQz65G3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ngrams(text, n_gram=1):\n",
        "    token = []\n",
        "    words = word_tokenize(text)\n",
        "    for w in words:\n",
        "        filter_words = STOPWORDS.union(set(string.punctuation))\n",
        "        if w not in filter_words:\n",
        "            token.append(w)\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
        "    return [' '.join(ngram) for ngram in ngrams]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvpJDPgG65G8",
        "colab_type": "text"
      },
      "source": [
        "## Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmwLZUHy65G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disaster_bigrams = defaultdict(int)\n",
        "nondisaster_bigrams = defaultdict(int)\n",
        "\n",
        "for tweet in train.loc[train['target'] == 1]['text_clean']:\n",
        "    for word in get_ngrams(tweet, 2):\n",
        "        disaster_bigrams[word] += 1\n",
        "        \n",
        "for tweet in train.loc[train['target'] == 0]['text_clean']:\n",
        "    for word in get_ngrams(tweet, 2):\n",
        "        nondisaster_bigrams[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ZNd8yp65HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nos mantenemos con los que tengan una frecuencia mayor o igual a 10 en desastre\n",
        "delete_keys = [k for k, v in disaster_bigrams.items() if v < 10]\n",
        "for key in delete_keys:\n",
        "    del disaster_bigrams[key]\n",
        "\n",
        "delete_keys = [k for k, v in nondisaster_bigrams.items() if v < 10]\n",
        "for key in delete_keys:\n",
        "    del nondisaster_bigrams[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszujeza65HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature booleano para saber si el texto tiene un bigrama de desastre o no\n",
        "\n",
        "train['text_disaster_bigram'] = train.text_clean.transform(lambda x: any(disngram in disaster_bigrams.keys() for disngram in get_ngrams(x, 2)))\n",
        "train['text_nondisaster_bigram'] = train.text_clean.transform(lambda x: any(disngram in nondisaster_bigrams.keys() for disngram in get_ngrams(x, 2)))\n",
        "test['text_disaster_bigram'] = test.text_clean.transform(lambda x: any(disngram in disaster_bigrams.keys() for disngram in get_ngrams(x, 2)))\n",
        "test['text_nondisaster_bigram'] = test.text_clean.transform(lambda x: any(disngram in nondisaster_bigrams.keys() for disngram in get_ngrams(x, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_OYoZM065HQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b1b516-c373-4d93-d283-5958b868e32b"
      },
      "source": [
        "train['text_disaster_bigram'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    6346\n",
              "True     1267\n",
              "Name: text_disaster_bigram, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqexcw0365HW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd68a685-4a91-4c5f-edf2-1467a9b3c55d"
      },
      "source": [
        "train['text_nondisaster_bigram'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    6749\n",
              "True     864 \n",
              "Name: text_nondisaster_bigram, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEXDBN_H65Hb",
        "colab_type": "text"
      },
      "source": [
        "## Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pih1CtNe65Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disaster_trigrams = defaultdict(int)\n",
        "nondisaster_trigrams = defaultdict(int)\n",
        "\n",
        "for tweet in train.loc[train['target'] == 1]['text_clean']:\n",
        "    for word in get_ngrams(tweet, 3):\n",
        "        disaster_trigrams[word] += 1\n",
        "        \n",
        "for tweet in train.loc[train['target'] == 0]['text_clean']:\n",
        "    for word in get_ngrams(tweet, 2):\n",
        "        nondisaster_trigrams[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlYBSL265Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nos mantenemos con los que tengan una frecuencia mayor o igual a 3\n",
        "delete_keys = [k for k, v in disaster_trigrams.items() if v < 3]\n",
        "for key in delete_keys:\n",
        "    del disaster_trigrams[key]\n",
        "\n",
        "delete_keys = [k for k, v in nondisaster_trigrams.items() if v < 3]\n",
        "for key in delete_keys:\n",
        "    del nondisaster_trigrams[key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJmiJqLi65Hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature booleano para saber si el texto tiene un bigrama de desastre o no\n",
        "\n",
        "train['text_disaster_trigram'] = train.text_clean.transform(lambda x: any(disngram in disaster_trigrams.keys() for disngram in get_ngrams(x, 3)))\n",
        "train['text_nondisaster_trigram'] = train.text_clean.transform(lambda x: any(disngram in nondisaster_trigrams.keys() for disngram in get_ngrams(x, 2)))\n",
        "test['text_disaster_trigram'] = test.text_clean.transform(lambda x: any(disngram in disaster_trigrams.keys() for disngram in get_ngrams(x, 3)))\n",
        "test['text_nondisaster_trigram'] = test.text_clean.transform(lambda x: any(disngram in nondisaster_trigrams.keys() for disngram in get_ngrams(x, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI7mSClD65Hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa3ad70-4c22-48ec-b318-e084b80c1f31"
      },
      "source": [
        "train['text_disaster_trigram'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    6384\n",
              "True     1229\n",
              "Name: text_disaster_trigram, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op8N4YQE65H2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba2923f-ee05-43da-e259-13801f0570cd"
      },
      "source": [
        "train['text_nondisaster_trigram'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    5462\n",
              "True     2151\n",
              "Name: text_nondisaster_trigram, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgnQ8ZvU65IB",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwHMkjWe65IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 1),\n",
        "    norm='l2',\n",
        "    min_df=0,\n",
        "    smooth_idf=False,\n",
        "    max_features=5000)\n",
        "X = vectorizer.fit_transform(train['text_clean'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMO5Zb5J65IH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fab62e0-5996-4e33-9eee-5df25d3095e1"
      },
      "source": [
        "df_tfidf = pd.DataFrame(X.todense(), columns = vectorizer.get_feature_names())\n",
        "df_tfidf.drop(labels = ['location','text', 'target'], axis=1, inplace=True)\n",
        "train = train.join(df_tfidf)\n",
        "print(train.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Columns: 5041 entries, keyword to zouma\n",
            "dtypes: bool(8), float64(5000), int64(27), object(6)\n",
            "memory usage: 292.4+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUzMa_gG65IM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465303e5-3e57-43c7-ab61-1de76a9bb8cd"
      },
      "source": [
        "X = vectorizer.transform(test['text_clean'])\n",
        "df_tfidf = pd.DataFrame(X.todense(), columns = vectorizer.get_feature_names())\n",
        "df_tfidf.drop(labels = ['id','location','text', 'target'], axis=1, inplace=True)\n",
        "test = test.join(df_tfidf)\n",
        "print(test.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Columns: 5056 entries, id to zouma\n",
            "dtypes: bool(21), float64(4999), int64(31), object(5)\n",
            "memory usage: 125.4+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJHzRrbC65IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f23a54-ce7e-4b8a-c525-5f17162ea08e"
      },
      "source": [
        "target = train.target\n",
        "train.drop(columns=['target'], inplace=True)\n",
        "train['target'] = target\n",
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Columns: 5041 entries, keyword to target\n",
            "dtypes: bool(8), float64(5000), int64(27), object(6)\n",
            "memory usage: 292.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QitrMee0_eYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5c8a44-d7c6-4f41-ae85-f2269dbc96b9"
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>keyword_grouped</th>\n",
              "      <th>text_contain_keyword</th>\n",
              "      <th>total_words</th>\n",
              "      <th>len_text</th>\n",
              "      <th>total_upper_chars</th>\n",
              "      <th>total_numbers_chars</th>\n",
              "      <th>total_special_chars</th>\n",
              "      <th>total_common_chars</th>\n",
              "      <th>contain_question</th>\n",
              "      <th>contain_link</th>\n",
              "      <th>contain_hashtag</th>\n",
              "      <th>contain_upper_words</th>\n",
              "      <th>total_3_words</th>\n",
              "      <th>total_4_words</th>\n",
              "      <th>total_5_words</th>\n",
              "      <th>total_6_words</th>\n",
              "      <th>total_7_words</th>\n",
              "      <th>total_8_words</th>\n",
              "      <th>total_3_ormore_words</th>\n",
              "      <th>total_4_ormore_words</th>\n",
              "      <th>total_5_ormore_words</th>\n",
              "      <th>total_6_ormore_words</th>\n",
              "      <th>total_7_ormore_words</th>\n",
              "      <th>total_8_ormore_words</th>\n",
              "      <th>total_3_orless_words</th>\n",
              "      <th>total_4_orless_words</th>\n",
              "      <th>total_5_orless_words</th>\n",
              "      <th>total_6_orless_words</th>\n",
              "      <th>total_7_orless_words</th>\n",
              "      <th>total_8_orless_words</th>\n",
              "      <th>subjectivity_text</th>\n",
              "      <th>polarity_text</th>\n",
              "      <th>stopword_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>mean_word_len</th>\n",
              "      <th>text_disaster_bigram</th>\n",
              "      <th>...</th>\n",
              "      <th>ya</th>\n",
              "      <th>yahoo</th>\n",
              "      <th>yahoonews</th>\n",
              "      <th>yall</th>\n",
              "      <th>yay</th>\n",
              "      <th>yazidis</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yemen</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yo</th>\n",
              "      <th>yobe</th>\n",
              "      <th>york</th>\n",
              "      <th>yorker</th>\n",
              "      <th>youd</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>youngheroesid</th>\n",
              "      <th>youre</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yugvani</th>\n",
              "      <th>yyc</th>\n",
              "      <th>z</th>\n",
              "      <th>z10</th>\n",
              "      <th>zakbagans</th>\n",
              "      <th>zayn</th>\n",
              "      <th>zionist</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zone</th>\n",
              "      <th>zouma</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>69</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>deeds reason earthquake may allah forgive us</td>\n",
              "      <td>4.384615</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>4.571429</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 5041 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  keyword location  ... zouma target\n",
              "0  NaN     NaN      ...  0.0   1    \n",
              "1  NaN     NaN      ...  0.0   1    \n",
              "\n",
              "[2 rows x 5041 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZGz1vq8As17",
        "colab_type": "text"
      },
      "source": [
        "## CREANDO EL CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-uv_uJSzJUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm_true_and_false(x):\n",
        "  if x is False:\n",
        "    return 0\n",
        "  return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlkXL6GwzNRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_cnnd=pd.DataFrame()\n",
        "train_cnnd=pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLbf0iwfy3OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"id\"]=train_ID.id\n",
        "test[\"len_text\"]=test.text.apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FqJZ_mEzSoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cnn[\"id\"]=train.id\n",
        "train_cnn[\"text_clean\"]=train.text_clean\n",
        "train_cnn[\"target\"]=train.target\n",
        "train_cnn[\"len_text\"]=train.len_text\n",
        "train_cnn[\"count_word_uniques\"]=train.total_words\n",
        "train_cnn[\"text_contain_keyword_norm\"]=train.text_contain_keyword.apply(lambda x:norm_true_and_false(x))\n",
        "train_cnn[\"contain_link_norm\"]=train.contain_link.apply(lambda x:norm_true_and_false(x))\n",
        "train_cnn[\"contain_question_norm\"]=train.contain_question.apply(lambda x:norm_true_and_false(x))\n",
        "train_cnn[\"contain_hashtag_norm\"]=train.contain_hashtag.apply(lambda x:norm_true_and_false(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxLDwvRzVx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_cnn[\"id\"]=test.id\n",
        "test_cnn[\"text_clean\"]=test.text_clean\n",
        "test_cnn[\"len_text\"]=test.len_text\n",
        "test_cnn[\"count_word_uniques\"]=test.total_words\n",
        "test_cnn[\"text_contain_keyword_norm\"]=test.text_contain_keyword.apply(lambda x:norm_true_and_false(x))\n",
        "test_cnn[\"contain_link_norm\"]=test.contain_link.apply(lambda x:norm_true_and_false(x))\n",
        "test_cnn[\"contain_question_norm\"]=test.contain_question.apply(lambda x:norm_true_and_false(x))\n",
        "test_cnn[\"contain_hashtag_norm\"]=test.contain_hashtag.apply(lambda x:norm_true_and_false(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K5T7wrC65Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('data/train_pre_processing_nlp_5000.csv', index=False)\n",
        "test.to_csv('data/test_pre_processing_nlp_5000.csv', index=False)\n",
        "train_cnn.to_csv('data/train_cnn.csv', index=False)\n",
        "test_cnn.to_csv('data/train_cnn.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}