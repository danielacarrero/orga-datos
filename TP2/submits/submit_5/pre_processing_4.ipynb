{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_pre_processing.csv\")\n",
    "test = pd.read_csv(\"data/test_pre_processing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_contain_keyword'] = train.text_contain_keyword.fillna(False).astype('bool')\n",
    "test['text_contain_keyword'] = test.text_contain_keyword.fillna(False).astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_contain_word_string(s,ws):\n",
    "    if pd.isna(ws):\n",
    "        return False\n",
    "    for w1 in ws.lower().split(\" \"):\n",
    "        for w2 in w1.split(\",\"):\n",
    "            for w3 in w2.split(\":\"):\n",
    "                for w in w3.split(\".\"):\n",
    "                    if len(w) > 3 and w in s.lower():\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "train['text_contain_word_location'] = train.apply(lambda x: string_contain_word_string(x.text,x.location), axis = 1)\n",
    "test['text_contain_word_location'] = test.apply(lambda x: string_contain_word_string(x.text,x.location), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['len_location_cero_default'] = train.location.transform(lambda x: 0 if pd.isna(x) else len(x))\n",
    "test['len_location_cero_default'] = test.location.transform(lambda x: 0 if pd.isna(x) else len(x))\n",
    "\n",
    "len_location_mean = int(train.loc[train.len_location_cero_default != 0,'len_location_cero_default'].mean())\n",
    "\n",
    "train['len_location_mean_default'] = train.len_location_cero_default.replace(0, len_location_mean)\n",
    "test['len_location_mean_default'] = test.len_location_cero_default.replace(0, len_location_mean)\n",
    "\n",
    "train['total_words_location_cero_default'] = train.location.transform(lambda x: 0 if pd.isna(x) else len(x.split(\" \")))\n",
    "test['total_words_location_cero_default'] = test.location.transform(lambda x: 0 if pd.isna(x) else len(x.split(\" \")))\n",
    "\n",
    "total_words_location_mean = int(train.loc[train.total_words_location_cero_default != 0,'total_words_location_cero_default'].mean())\n",
    "\n",
    "train['total_words_location_mean_default'] = train.total_words_location_cero_default.replace(0, total_words_location_mean)\n",
    "test['total_words_location_mean_default'] = test.total_words_location_cero_default.replace(0, total_words_location_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_contain_similarity_word(x,y):\n",
    "    if pd.isna(y):\n",
    "        return False\n",
    "    \n",
    "    for w in x.lower().split(\" \"):\n",
    "        if fuzz.ratio(w,y.lower()) > 80:\n",
    "            return True\n",
    "    return False \n",
    "\n",
    "train['text_contain_keyword_similarity'] = train.apply(lambda x: text_contain_similarity_word(x.text,x.keyword_grouped), axis = 1)\n",
    "test['text_contain_keyword_similarity'] = test.apply(lambda x: text_contain_similarity_word(x.text,x.keyword_grouped), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_similarity_keyword'] = train.apply(lambda x: 0 if pd.isna(x.keyword_grouped) else fuzz.ratio(x.text.lower(),x.keyword_grouped.lower()), axis = 1)\n",
    "test['text_similarity_keyword'] = test.apply(lambda x: 0 if pd.isna(x.keyword_grouped) else fuzz.ratio(x.text.lower(),x.keyword_grouped.lower()), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_similarity(s,w):\n",
    "    similarity = 0\n",
    "    \n",
    "    for x in s.split(\" \"):\n",
    "        if fuzz.ratio(x,w) > similarity:\n",
    "            similarity = fuzz.ratio(x,w)\n",
    "    return similarity\n",
    "\n",
    "train['text_best_similarity_keyword'] = train.apply(lambda x: 0 if pd.isna(x.keyword_grouped) else get_best_similarity(x.text.lower(),x.keyword_grouped.lower()), axis = 1)\n",
    "test['text_best_similarity_keyword'] = test.apply(lambda x: 0 if pd.isna(x.keyword_grouped) else get_best_similarity(x.text.lower(),x.keyword_grouped.lower()), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_similarity_location'] = train.apply(lambda x: 0 if pd.isna(x.location) else fuzz.ratio(x.text.lower(),x.location.lower()), axis = 1)\n",
    "test['text_similarity_location'] = test.apply(lambda x: 0 if pd.isna(x.location) else fuzz.ratio(x.text.lower(),x.location.lower()), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_best_similarity_location'] = train.apply(lambda x: 0 if pd.isna(x.location) else get_best_similarity(x.text.lower(),x.location.lower()), axis = 1)\n",
    "test['text_best_similarity_location'] = test.apply(lambda x: 0 if pd.isna(x.location) else get_best_similarity(x.text.lower(),x.location.lower()), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ratio_short_big_words']  = train['total_3_orless_words'] / train['total_5_ormore_words'].replace(0,1)\n",
    "test['ratio_short_big_words']  = test['total_3_orless_words'] / test['total_5_ormore_words'].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['subjectivity_text', 'text_best_similarity_location', 'text_similarity_location', 'total_4_words', 'total_4_ormore_words', 'total_7_words', 'total_4_orless_words', 'len_location_mean_default'],inplace = True)\n",
    "test.drop( columns=['subjectivity_text', 'text_best_similarity_location', 'text_similarity_location', 'total_4_words', 'total_4_ormore_words', 'total_7_words', 'total_4_orless_words', 'len_location_mean_default'],inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = {}\n",
    "for x in train.loc[:,['text','target']].iterrows():\n",
    "    for word in re.split(' |\\'|\\*|\\n|:|#|@|-|\\?|\\.|,|[|]|!|ยก',x[1]['text']):\n",
    "        word = word.lower()\n",
    "        if len(word) < 4:\n",
    "            continue\n",
    "        if not word in words_dict:\n",
    "            words_dict[word] = [0,0]\n",
    "        if x[1]['target'] == 1:\n",
    "            words_dict[word][0] = words_dict[word][0] + 1\n",
    "        else:\n",
    "            words_dict[word][1] = words_dict[word][1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_dict,index=['total_target_true','total_target_false']).transpose()\n",
    "words_df = words_df.loc[(words_df.total_target_true + words_df.total_target_false) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_100_true = []\n",
    "words_100_false = []\n",
    "words_90_true = []\n",
    "words_90_false = []\n",
    "words_85_true = []\n",
    "words_85_false = []\n",
    "words_80_true = []\n",
    "words_80_false = []\n",
    "words_75_true = []\n",
    "words_75_false = []\n",
    "words_70_true = []\n",
    "words_70_false = []\n",
    "\n",
    "\n",
    "for word in words_df.iterrows():\n",
    "    false = word[1]['total_target_false']\n",
    "    true = word[1]['total_target_true']\n",
    "    \n",
    "    if true == 0:\n",
    "        words_100_false.append(word[0])\n",
    "        \n",
    "    if false == 0:\n",
    "        words_100_true.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.9:\n",
    "        words_90_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.9:\n",
    "        words_90_false.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.85:\n",
    "        words_85_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.85:\n",
    "        words_85_false.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.8:\n",
    "        words_80_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.8:\n",
    "        words_80_false.append(word[0])\n",
    "\n",
    "    if true / (true + false) >= 0.75:\n",
    "        words_75_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.75:\n",
    "        words_75_false.append(word[0])\n",
    "        \n",
    "    if true / (true + false) >= 0.7:\n",
    "        words_70_true.append(word[0])\n",
    "\n",
    "    if false / (true + false) >= 0.7:\n",
    "        words_70_false.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_contain_word_list(s,l):\n",
    "    for word in l:\n",
    "        if word.lower() in s.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['contain_words_100_true'] = train.text.transform(lambda x: text_contain_word_list(x,words_100_true))\n",
    "train['contain_words_100_false'] = train.text.transform(lambda x: text_contain_word_list(x,words_100_false))\n",
    "train['contain_words_90_true'] = train.text.transform(lambda x: text_contain_word_list(x,words_90_true))\n",
    "train['contain_words_90_false'] = train.text.transform(lambda x: text_contain_word_list(x,words_90_false))\n",
    "train['contain_words_85_true'] = train.text.transform(lambda x: text_contain_word_list(x,words_85_true))\n",
    "train['contain_words_85_false'] = train.text.transform(lambda x: text_contain_word_list(x,words_85_false))\n",
    "train['contain_words_80_true'] = train.text.transform(lambda x: text_contain_word_list(x,words_80_true))\n",
    "train['contain_words_80_false'] = train.text.transform(lambda x: text_contain_word_list(x,words_80_false))\n",
    "train['contain_words_75_true'] = train.text.transform(lambda x: text_contain_word_list(x,words_75_true))\n",
    "train['contain_words_75_false'] = train.text.transform(lambda x: text_contain_word_list(x,words_75_false))\n",
    "train['contain_words_70_true'] = train.text.transform(lambda x: text_contain_word_list(x,words_70_true))\n",
    "train['contain_words_70_false'] = train.text.transform(lambda x: text_contain_word_list(x,words_70_false))\n",
    "\n",
    "test['contain_words_100_true'] = test.text.transform(lambda x: text_contain_word_list(x,words_100_true))\n",
    "test['contain_words_100_false'] = test.text.transform(lambda x: text_contain_word_list(x,words_100_false))\n",
    "test['contain_words_90_true'] = test.text.transform(lambda x: text_contain_word_list(x,words_90_true))\n",
    "test['contain_words_90_false'] = test.text.transform(lambda x: text_contain_word_list(x,words_90_false))\n",
    "test['contain_words_85_true'] = test.text.transform(lambda x: text_contain_word_list(x,words_85_true))\n",
    "test['contain_words_85_false'] = test.text.transform(lambda x: text_contain_word_list(x,words_85_false))\n",
    "test['contain_words_80_true'] = test.text.transform(lambda x: text_contain_word_list(x,words_80_true))\n",
    "test['contain_words_80_false'] = test.text.transform(lambda x: text_contain_word_list(x,words_80_false))\n",
    "test['contain_words_75_true'] = test.text.transform(lambda x: text_contain_word_list(x,words_75_true))\n",
    "test['contain_words_75_false'] = test.text.transform(lambda x: text_contain_word_list(x,words_75_false))\n",
    "test['contain_words_70_true'] = test.text.transform(lambda x: text_contain_word_list(x,words_70_true))\n",
    "test['contain_words_70_false'] = test.text.transform(lambda x: text_contain_word_list(x,words_70_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['len_text', 'contain_words_75_false', 'total_7_ormore_words', 'contain_words_100_false', 'total_common_chars', 'total_7_orless_words'],inplace = True)\n",
    "test.drop( columns=['len_text', 'contain_words_75_false', 'total_7_ormore_words', 'contain_words_100_false', 'total_common_chars', 'total_7_orless_words'],inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_OHE(df,word_list):\n",
    "    for word in word_list:\n",
    "        is_Ascii = True\n",
    "        for c in word:\n",
    "            if ord(c) > 127 or ord(c) < 0:\n",
    "                is_Ascii = False\n",
    "                break\n",
    "        if not is_Ascii:\n",
    "            continue\n",
    "        df[word+'_OHE'] = df.text.transform(lambda y: word.lower() in y.lower())\n",
    "    return df\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true = get_features_OHE(train.copy(),words_70_true)\n",
    "test_true = get_features_OHE(test.copy(),words_70_true)\n",
    "train_false = get_features_OHE(train.copy(),words_70_false)\n",
    "test_false = get_features_OHE(test.copy(),words_70_false)\n",
    "train_true_false = get_features_OHE(train_false.copy(),words_70_true)\n",
    "test_true_false = get_features_OHE(test_false.copy(),words_70_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_true.target\n",
    "train_true.drop(columns=['target'], inplace=True)\n",
    "train_true['target'] = target\n",
    "\n",
    "target = train_false.target\n",
    "train_false.drop(columns=['target'], inplace=True)\n",
    "train_false['target'] = target\n",
    "\n",
    "target = train_true_false.target\n",
    "train_true_false.drop(columns=['target'], inplace=True)\n",
    "train_true_false['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true.to_csv('data/train_pre_processing_true.csv', index=False)\n",
    "test_true.to_csv('data/test_pre_processing_true.csv', index=False)\n",
    "train_false.to_csv('data/train_pre_processing_false.csv', index=False)\n",
    "test_false.to_csv('data/test_pre_processing_false.csv', index=False)\n",
    "train_true_false.to_csv('data/train_pre_processing_true_false.csv', index=False)\n",
    "test_true_false.to_csv('data/test_pre_processing_true_false.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
